{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavm24/EIP/blob/master/week4/Assignment4/Cifar-10-resnet-18-gradcam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECSvH-R271u6",
        "colab_type": "code",
        "outputId": "1337bb2c-f74c-4135-b818-ba5048e33ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "!pip install keras --upgrade"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAQKnhDV5Uml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "672db247-7f04-4249-df5e-f9ecfe2f0733"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqa6cEFo5Xg4",
        "colab_type": "code",
        "outputId": "0ee3829d-5309-473a-bdb6-6334737e7786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 2 #change here\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 2\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "n, version, model_type"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2, 'ResNet20v2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOs6E7y87FHV",
        "colab_type": "code",
        "outputId": "73acf698-8a30-45fb-b9fe-3108cbfc9fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj1jTuAI5gP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 10:\n",
        "        lr *= 1e-1\n",
        "    elif epoch > 15:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 25:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 35:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgtJqtPD55Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=64, #change here\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCFB43MM7SVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KdtDYXp57ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 64 #change here\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHSS08PdduE",
        "colab_type": "code",
        "outputId": "27460927-7763-47a3-9518-3858a30007dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_shape, depth, version"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 32, 3), 20, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTCqTTY75_Yz",
        "colab_type": "code",
        "outputId": "2a0acd13-1405-4382-c671-236f75b9f8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Learning rate:  0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   4160        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 256)  16640       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 256)  0           add_1[0][0]                      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 256)  65792       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  131584      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 512)  131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 512)  0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 256)  131328      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 256)  590080      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 512)  131584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 512)  0           add_3[0][0]                      \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 512)    262656      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 512)    2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 512)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 512)    2359808     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 512)    2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 512)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 1024)   525312      add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 1024)   525312      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 1024)   0           conv2d_19[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 1024)   4096        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 512)    524800      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 512)    2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 512)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 512)    2359808     activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 512)    2048        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 512)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 1024)   525312      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 1024)   0           add_5[0][0]                      \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 1024)   4096        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 1024)   0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1024)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           10250       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 9,039,370\n",
            "Trainable params: 9,025,418\n",
            "Non-trainable params: 13,952\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOU9LmJ56fKy",
        "colab_type": "code",
        "outputId": "3d512d64-3218-46a4-e1bd-e28fdb48df9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 73s 187ms/step - loss: 2.5506 - accuracy: 0.5175 - val_loss: 2.1167 - val_accuracy: 0.5480\n",
            "Epoch 2/50\n",
            "Learning rate:  0.001\n",
            "  1/391 [..............................] - ETA: 58s - loss: 1.9196 - accuracy: 0.5859"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 62s 158ms/step - loss: 1.6611 - accuracy: 0.6511 - val_loss: 2.2985 - val_accuracy: 0.4858\n",
            "Epoch 3/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 62s 158ms/step - loss: 1.3391 - accuracy: 0.7124 - val_loss: 1.7202 - val_accuracy: 0.5972\n",
            "Epoch 4/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 62s 158ms/step - loss: 1.1704 - accuracy: 0.7467 - val_loss: 1.5958 - val_accuracy: 0.6088\n",
            "Epoch 5/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 61s 157ms/step - loss: 1.0802 - accuracy: 0.7675 - val_loss: 1.2947 - val_accuracy: 0.6901\n",
            "Epoch 6/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 62s 158ms/step - loss: 1.0066 - accuracy: 0.7821 - val_loss: 1.7462 - val_accuracy: 0.5900\n",
            "Epoch 7/50\n",
            "Learning rate:  0.001\n",
            "  6/391 [..............................] - ETA: 57s - loss: 0.9371 - accuracy: 0.8060"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-12-17e66239e209>\", line 62, in <module>\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1732, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\", line 220, in fit_generator\n",
            "    reset_metrics=False)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1514, in train_on_batch\n",
            "    outputs = self.train_function(ins)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
            "    run_metadata=self.run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 68, in <module>\n",
            "    from tensorflow.contrib import mixed_precision\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/mixed_precision/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.contrib.mixed_precision.python.loss_scale_manager import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/mixed_precision/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.contrib.mixed_precision.python.loss_scale_manager import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/mixed_precision/python/loss_scale_manager.py\", line 104, in <module>\n",
            "    class ExponentialUpdateLossScaleManager(LossScaleManager):\n",
            "  File \"/usr/lib/python3.6/abc.py\", line 136, in __new__\n",
            "    for name, value in namespace.items()\n",
            "  File \"/usr/lib/python3.6/abc.py\", line 137, in <setcomp>\n",
            "    if getattr(value, \"__isabstractmethod__\", False)}\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loymD5GwhRP6",
        "colab_type": "text"
      },
      "source": [
        "# Grad cam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvZstu1Jk5EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import io\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "\n",
        "labels = {0 : 'airplane',1 : 'automobile',2 : 'bird',3 : 'cat',4 : 'deer',5 : 'dog',6 : 'frog',\n",
        "7 : 'horse',8 : 'ship',9 : 'truck'}\n",
        "def grad_cam(img,layer = 'conv2d_21'):\n",
        "  img = cv2.resize(img,dsize = (32,32), interpolation=cv2.INTER_CUBIC)\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img,axis = 0)\n",
        "  pred = model.predict(img)\n",
        "  pred_id = np.argmax(pred[0])\n",
        "  class_output = model.output[:,pred_id]\n",
        "  last_layer = model.get_layer(layer)\n",
        "\n",
        "  grads = K.gradients(class_output, last_layer.output)[0]\n",
        "  pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "  iterate = K.function([model.input], [pooled_grads, last_layer.output[0]])\n",
        "  pooled_grads_value, conv_layer_output_value = iterate([img])\n",
        "  for i in range(128):\n",
        "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "\n",
        "  heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "  heatmap /= np.max(heatmap)\n",
        "\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[2]))\n",
        "  heatmap = np.uint8(heatmap * 255.0)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  superimposed_img = cv2.addWeighted(img[0], 0.5 , heatmap, 0.5, 0,dtype=cv2.CV_64F)\n",
        "  return(img[0],heatmap,superimposed_img[...,::-1],pred_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgDIJ8GEk6Qw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "7d821e96-6de5-4f8f-8b79-503f8b1fee43"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def normalize(img):\n",
        "    return np.uint8((img - img.min()) / (img.max()-img.min())*255)\n",
        "\n",
        "ind = np.random.choice(len(x_test),size = 6,replace = False)\n",
        "plt.figure(figsize = (30,10))\n",
        "for i in range(len(ind)):\n",
        "  img,heatmap,superimposed_img,pred_id = grad_cam(x_test[ind[i]],layer = 'conv2d_21')\n",
        "  ax = plt.subplot(2,4,i+1)\n",
        "  ax.imshow(img)\n",
        "  ax.imshow(normalize(superimposed_img),alpha = 0.4)\n",
        "  ax.set_title('prediction: {} \\n actual_label: {}'.format(labels[pred_id],labels[np.argmax(y_test[ind[i]])]))\n",
        "  plt.tight_layout()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB5UAAALICAYAAABfFqfMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJeSt/70Y/dgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 2160x720 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wbEmp97k6kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBa3sDSP7e_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "from skimage import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrjCnj7BhS2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GradCam(input_img):\n",
        "    input_img = io.imread(input_img)\n",
        "    input_img = cv2.resize(input_img, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "    x = image.img_to_array(input_img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)   \n",
        "\n",
        "    preds = model.predict(x)\n",
        "    class_idx = np.argmax(preds[0])\n",
        "    print(class_idx)\n",
        "    class_output = model.output[:, class_idx]\n",
        "    last_conv_layer = model.get_layer(\"activation_57\") \n",
        "\n",
        "    from keras import backend as K\n",
        "    grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "    print(grads.shape)\n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "    print(pooled_grads.shape)\n",
        "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "    pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "    for i in range(512):\n",
        "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]    \n",
        "\n",
        "    heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "    print(conv_layer_output_value.shape)\n",
        "    print(heatmap.shape)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    heatmap = cv2.resize(heatmap, (input_img.shape[1], input_img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(input_img, 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "    return input_img, superimposed_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3GmgmFExc5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}