{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 30 19:53:33 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   46C    P0    26W / 300W |      0MiB / 16130MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonAttributes.ipynb\tREADME.md  hvc_annotations.csv\thvc_data.zip  resized\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path \n",
    "from tqdm import tqdm\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler, Callback\n",
    "\n",
    "\n",
    "# from keras.applications import VGG16\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, Dropout, Flatten, Dense, Input, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>imagequality</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>carryingbag</th>\n",
       "      <th>footwear</th>\n",
       "      <th>emotion</th>\n",
       "      <th>bodypose</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>Average</td>\n",
       "      <td>35-45</td>\n",
       "      <td>normal-healthy</td>\n",
       "      <td>Grocery/Home/Plastic Bag</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>Average</td>\n",
       "      <td>35-45</td>\n",
       "      <td>over-weight</td>\n",
       "      <td>None</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Angry/Serious</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>Good</td>\n",
       "      <td>45-55</td>\n",
       "      <td>normal-healthy</td>\n",
       "      <td>Grocery/Home/Plastic Bag</td>\n",
       "      <td>CantSee</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Good</td>\n",
       "      <td>45-55</td>\n",
       "      <td>normal-healthy</td>\n",
       "      <td>Daily/Office/Work Bag</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Good</td>\n",
       "      <td>35-45</td>\n",
       "      <td>slightly-overweight</td>\n",
       "      <td>None</td>\n",
       "      <td>CantSee</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender imagequality    age               weight               carryingbag  \\\n",
       "0    male      Average  35-45       normal-healthy  Grocery/Home/Plastic Bag   \n",
       "1  female      Average  35-45          over-weight                      None   \n",
       "2    male         Good  45-55       normal-healthy  Grocery/Home/Plastic Bag   \n",
       "3    male         Good  45-55       normal-healthy     Daily/Office/Work Bag   \n",
       "4  female         Good  35-45  slightly-overweight                      None   \n",
       "\n",
       "  footwear        emotion        bodypose     image_path  \n",
       "0   Normal        Neutral  Front-Frontish  resized/1.jpg  \n",
       "1   Normal  Angry/Serious  Front-Frontish  resized/2.jpg  \n",
       "2  CantSee        Neutral  Front-Frontish  resized/3.jpg  \n",
       "3   Normal        Neutral  Front-Frontish  resized/4.jpg  \n",
       "4  CantSee        Neutral  Front-Frontish  resized/5.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load annotations\n",
    "df = pd.read_csv(\"hvc_annotations.csv\")\n",
    "del df[\"filename\"] # remove unwanted column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_path</th>\n",
       "      <td>resized/1.jpg</td>\n",
       "      <td>resized/2.jpg</td>\n",
       "      <td>resized/3.jpg</td>\n",
       "      <td>resized/4.jpg</td>\n",
       "      <td>resized/5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_female</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_male</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Average</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Bad</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Good</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_15-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_25-35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_35-45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_45-55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_55+</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_normal-healthy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_over-weight</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_slightly-overweight</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_underweight</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_None</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_CantSee</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_Fancy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_Normal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Angry/Serious</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Happy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Neutral</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Sad</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Back</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Front-Frontish</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Side</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0              1  \\\n",
       "image_path                            resized/1.jpg  resized/2.jpg   \n",
       "gender_female                                     0              1   \n",
       "gender_male                                       1              0   \n",
       "imagequality_Average                              1              1   \n",
       "imagequality_Bad                                  0              0   \n",
       "imagequality_Good                                 0              0   \n",
       "age_15-25                                         0              0   \n",
       "age_25-35                                         0              0   \n",
       "age_35-45                                         1              1   \n",
       "age_45-55                                         0              0   \n",
       "age_55+                                           0              0   \n",
       "weight_normal-healthy                             1              0   \n",
       "weight_over-weight                                0              1   \n",
       "weight_slightly-overweight                        0              0   \n",
       "weight_underweight                                0              0   \n",
       "carryingbag_Daily/Office/Work Bag                 0              0   \n",
       "carryingbag_Grocery/Home/Plastic Bag              1              0   \n",
       "carryingbag_None                                  0              1   \n",
       "footwear_CantSee                                  0              0   \n",
       "footwear_Fancy                                    0              0   \n",
       "footwear_Normal                                   1              1   \n",
       "emotion_Angry/Serious                             0              1   \n",
       "emotion_Happy                                     0              0   \n",
       "emotion_Neutral                                   1              0   \n",
       "emotion_Sad                                       0              0   \n",
       "bodypose_Back                                     0              0   \n",
       "bodypose_Front-Frontish                           1              1   \n",
       "bodypose_Side                                     0              0   \n",
       "\n",
       "                                                  2              3  \\\n",
       "image_path                            resized/3.jpg  resized/4.jpg   \n",
       "gender_female                                     0              0   \n",
       "gender_male                                       1              1   \n",
       "imagequality_Average                              0              0   \n",
       "imagequality_Bad                                  0              0   \n",
       "imagequality_Good                                 1              1   \n",
       "age_15-25                                         0              0   \n",
       "age_25-35                                         0              0   \n",
       "age_35-45                                         0              0   \n",
       "age_45-55                                         1              1   \n",
       "age_55+                                           0              0   \n",
       "weight_normal-healthy                             1              1   \n",
       "weight_over-weight                                0              0   \n",
       "weight_slightly-overweight                        0              0   \n",
       "weight_underweight                                0              0   \n",
       "carryingbag_Daily/Office/Work Bag                 0              1   \n",
       "carryingbag_Grocery/Home/Plastic Bag              1              0   \n",
       "carryingbag_None                                  0              0   \n",
       "footwear_CantSee                                  1              0   \n",
       "footwear_Fancy                                    0              0   \n",
       "footwear_Normal                                   0              1   \n",
       "emotion_Angry/Serious                             0              0   \n",
       "emotion_Happy                                     0              0   \n",
       "emotion_Neutral                                   1              1   \n",
       "emotion_Sad                                       0              0   \n",
       "bodypose_Back                                     0              0   \n",
       "bodypose_Front-Frontish                           1              1   \n",
       "bodypose_Side                                     0              0   \n",
       "\n",
       "                                                  4  \n",
       "image_path                            resized/5.jpg  \n",
       "gender_female                                     1  \n",
       "gender_male                                       0  \n",
       "imagequality_Average                              0  \n",
       "imagequality_Bad                                  0  \n",
       "imagequality_Good                                 1  \n",
       "age_15-25                                         0  \n",
       "age_25-35                                         0  \n",
       "age_35-45                                         1  \n",
       "age_45-55                                         0  \n",
       "age_55+                                           0  \n",
       "weight_normal-healthy                             0  \n",
       "weight_over-weight                                0  \n",
       "weight_slightly-overweight                        1  \n",
       "weight_underweight                                0  \n",
       "carryingbag_Daily/Office/Work Bag                 0  \n",
       "carryingbag_Grocery/Home/Plastic Bag              0  \n",
       "carryingbag_None                                  1  \n",
       "footwear_CantSee                                  1  \n",
       "footwear_Fancy                                    0  \n",
       "footwear_Normal                                   0  \n",
       "emotion_Angry/Serious                             0  \n",
       "emotion_Happy                                     0  \n",
       "emotion_Neutral                                   1  \n",
       "emotion_Sad                                       0  \n",
       "bodypose_Back                                     0  \n",
       "bodypose_Front-Frontish                           1  \n",
       "bodypose_Side                                     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding of labels\n",
    "\n",
    "one_hot_df = pd.concat([\n",
    "    df[[\"image_path\"]],\n",
    "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
    "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
    "    pd.get_dummies(df.age, prefix=\"age\"),\n",
    "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
    "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
    "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
    "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
    "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
    "], axis = 1)\n",
    "\n",
    "one_hot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "# Label columns per attribute\n",
    "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
    "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
    "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
    "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
    "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
    "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
    "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
    "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
    "\n",
    "class PersonDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Ground truth data generator\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, df, batch_size=32, shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"fetch batched images and targets\"\"\"\n",
    "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
    "        items = self.df.iloc[batch_slice]\n",
    "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
    "        target = {\n",
    "            \"gender_output\": items[_gender_cols_].values,\n",
    "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
    "            \"age_output\": items[_age_cols_].values,\n",
    "            \"weight_output\": items[_weight_cols_].values,\n",
    "            \"bag_output\": items[_carryingbag_cols_].values,\n",
    "            \"pose_output\": items[_bodypose_cols_].values,\n",
    "            \"footwear_output\": items[_footwear_cols_].values,\n",
    "            \"emotion_output\": items[_emotion_cols_].values,\n",
    "        }\n",
    "        return image, target\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        if self.shuffle == True:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11537, 28), (2036, 28))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state = 42)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>imagequality_Average</th>\n",
       "      <th>imagequality_Bad</th>\n",
       "      <th>imagequality_Good</th>\n",
       "      <th>age_15-25</th>\n",
       "      <th>age_25-35</th>\n",
       "      <th>age_35-45</th>\n",
       "      <th>age_45-55</th>\n",
       "      <th>...</th>\n",
       "      <th>footwear_CantSee</th>\n",
       "      <th>footwear_Fancy</th>\n",
       "      <th>footwear_Normal</th>\n",
       "      <th>emotion_Angry/Serious</th>\n",
       "      <th>emotion_Happy</th>\n",
       "      <th>emotion_Neutral</th>\n",
       "      <th>emotion_Sad</th>\n",
       "      <th>bodypose_Back</th>\n",
       "      <th>bodypose_Front-Frontish</th>\n",
       "      <th>bodypose_Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10416</th>\n",
       "      <td>resized/10418.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>resized/3496.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>resized/6951.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>resized/5036.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>resized/4411.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_path  gender_female  gender_male  imagequality_Average  \\\n",
       "10416  resized/10418.jpg              0            1                     1   \n",
       "3495    resized/3496.jpg              0            1                     0   \n",
       "6950    resized/6951.jpg              1            0                     0   \n",
       "5035    resized/5036.jpg              1            0                     1   \n",
       "4410    resized/4411.jpg              1            0                     0   \n",
       "\n",
       "       imagequality_Bad  imagequality_Good  age_15-25  age_25-35  age_35-45  \\\n",
       "10416                 0                  0          0          1          0   \n",
       "3495                  0                  1          0          1          0   \n",
       "6950                  0                  1          0          1          0   \n",
       "5035                  0                  0          0          0          0   \n",
       "4410                  1                  0          0          1          0   \n",
       "\n",
       "       age_45-55  ...  footwear_CantSee  footwear_Fancy  footwear_Normal  \\\n",
       "10416          0  ...                 0               0                1   \n",
       "3495           0  ...                 1               0                0   \n",
       "6950           0  ...                 1               0                0   \n",
       "5035           1  ...                 0               0                1   \n",
       "4410           0  ...                 1               0                0   \n",
       "\n",
       "       emotion_Angry/Serious  emotion_Happy  emotion_Neutral  emotion_Sad  \\\n",
       "10416                      0              0                1            0   \n",
       "3495                       0              0                1            0   \n",
       "6950                       0              0                1            0   \n",
       "5035                       0              0                1            0   \n",
       "4410                       0              0                1            0   \n",
       "\n",
       "       bodypose_Back  bodypose_Front-Frontish  bodypose_Side  \n",
       "10416              1                        0              0  \n",
       "3495               1                        0              0  \n",
       "6950               0                        0              1  \n",
       "5035               0                        1              0  \n",
       "4410               0                        0              1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation data generators\n",
    "train_gen = PersonDataGenerator(train_df, batch_size=32)\n",
    "valid_gen = PersonDataGenerator(train_df, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 2,\n",
       " 'image_quality': 3,\n",
       " 'age': 5,\n",
       " 'weight': 4,\n",
       " 'bag': 3,\n",
       " 'pose': 3,\n",
       " 'footwear': 3,\n",
       " 'emotion': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of output units from data\n",
    "images, targets = next(iter(train_gen))\n",
    "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
    "num_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 32) 128         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 32) 9216        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 224, 224, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 224, 224, 32) 128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 64) 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 112, 112, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 64) 256         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 64) 36864       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 112, 112, 64) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 112, 112, 64) 256         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 128)  73728       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 128)  512         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 128)  147456      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 128)  512         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 256)  294912      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 256)  1024        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 256)  589824      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 28, 28, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 28, 28, 256)  1024        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 16)   4096        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 28, 28, 16)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 16)   64          activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 16)           0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8)            136         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            136         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gender_output (Dense)           (None, 2)            18          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_quality_output (Dense)    (None, 3)            27          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "age_output (Dense)              (None, 5)            45          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "weight_output (Dense)           (None, 4)            36          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bag_output (Dense)              (None, 3)            27          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "footwear_output (Dense)         (None, 3)            27          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pose_output (Dense)             (None, 3)            27          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "emotion_output (Dense)          (None, 4)            36          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,180,627\n",
      "Trainable params: 1,178,675\n",
      "Non-trainable params: 1,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "inputs = Input(shape=(224,224,3))\n",
    "\n",
    "def get_conv_block(num_filters, prev_layer, kernel_size=3, strides=1):\n",
    "    return BatchNormalization()(Activation('relu')(Conv2D(num_filters,\n",
    "       kernel_size=kernel_size,\n",
    "       padding='same',\n",
    "       strides=strides,\n",
    "       kernel_regularizer=l2(weight_decay),\n",
    "       use_bias=False)(prev_layer)))\n",
    "\n",
    "num_filters = 32\n",
    "block1 = get_conv_block(num_filters, inputs)\n",
    "block1 = get_conv_block(num_filters, block1)\n",
    "block1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(block1)\n",
    "\n",
    "num_filters = 64\n",
    "block2 = get_conv_block(num_filters, block1)\n",
    "block2 = get_conv_block(num_filters, block2)\n",
    "block2 = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(block2)\n",
    "\n",
    "num_filters = 128\n",
    "block3 = get_conv_block(num_filters, block2)\n",
    "block3 = get_conv_block(num_filters, block3)\n",
    "block3 = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(block3)\n",
    "\n",
    "num_filters = 256\n",
    "block4 = get_conv_block(num_filters, block3)\n",
    "block4 = get_conv_block(num_filters, block4)\n",
    "\n",
    "#bottleneck\n",
    "num_filters = 16\n",
    "block5 = get_conv_block(num_filters, block4, kernel_size=1)\n",
    "\n",
    "#GAP\n",
    "block6 = GlobalAveragePooling2D()(block5)\n",
    "\n",
    "neck = block6\n",
    "\n",
    "#multi label output\n",
    "def build_tower(in_layer):\n",
    "    neck = Dropout(0.2)(in_layer)\n",
    "    neck = Dense(8, activation=\"relu\")(neck)\n",
    "    return neck\n",
    "\n",
    "def build_head(name, in_layer):\n",
    "    return Dense(\n",
    "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
    "    )(in_layer)\n",
    "\n",
    "# heads\n",
    "gender = build_head(\"gender\", build_tower(neck))\n",
    "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
    "age = build_head(\"age\", build_tower(neck))\n",
    "weight = build_head(\"weight\", build_tower(neck))\n",
    "bag = build_head(\"bag\", build_tower(neck))\n",
    "footwear = build_head(\"footwear\", build_tower(neck))\n",
    "emotion = build_head(\"emotion\", build_tower(neck))\n",
    "pose = build_head(\"pose\", build_tower(neck))\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    inputs=inputs, \n",
    "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch, lr=1e-3):\n",
    "    if epoch > 30:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 60:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "360/360 [==============================] - 46s 127ms/step - loss: 8.1890 - gender_output_loss: 0.6828 - image_quality_output_loss: 0.9915 - age_output_loss: 1.5033 - weight_output_loss: 1.0486 - bag_output_loss: 0.9515 - footwear_output_loss: 0.9968 - pose_output_loss: 0.9490 - emotion_output_loss: 0.9919 - gender_output_acc: 0.5678 - image_quality_output_acc: 0.5439 - age_output_acc: 0.3819 - weight_output_acc: 0.6313 - bag_output_acc: 0.5497 - footwear_output_acc: 0.5378 - pose_output_acc: 0.6109 - emotion_output_acc: 0.7113 - val_loss: 8.0307 - val_gender_output_loss: 0.6928 - val_image_quality_output_loss: 0.9521 - val_age_output_loss: 1.4503 - val_weight_output_loss: 1.0386 - val_bag_output_loss: 0.9292 - val_footwear_output_loss: 1.0498 - val_pose_output_loss: 0.9441 - val_emotion_output_loss: 0.9121 - val_gender_output_acc: 0.5404 - val_image_quality_output_acc: 0.5516 - val_age_output_acc: 0.4010 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5391 - val_footwear_output_acc: 0.5168 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.7129\n",
      "Epoch 2/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 7.8038 - gender_output_loss: 0.6754 - image_quality_output_loss: 0.9397 - age_output_loss: 1.4295 - weight_output_loss: 0.9906 - bag_output_loss: 0.9150 - footwear_output_loss: 0.9515 - pose_output_loss: 0.9323 - emotion_output_loss: 0.9112 - gender_output_acc: 0.5707 - image_quality_output_acc: 0.5543 - age_output_acc: 0.3971 - weight_output_acc: 0.6329 - bag_output_acc: 0.5632 - footwear_output_acc: 0.5611 - pose_output_acc: 0.6169 - emotion_output_acc: 0.7127 - val_loss: 8.0733 - val_gender_output_loss: 0.6843 - val_image_quality_output_loss: 1.0792 - val_age_output_loss: 1.4498 - val_weight_output_loss: 1.0116 - val_bag_output_loss: 0.9333 - val_footwear_output_loss: 0.9997 - val_pose_output_loss: 0.9360 - val_emotion_output_loss: 0.9234 - val_gender_output_acc: 0.5701 - val_image_quality_output_acc: 0.4270 - val_age_output_acc: 0.4006 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5636 - val_footwear_output_acc: 0.5392 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.7129\n",
      "Epoch 3/100\n",
      "359/360 [============================>.] - ETA: 0s - loss: 7.6882 - gender_output_loss: 0.6576 - image_quality_output_loss: 0.9128 - age_output_loss: 1.4212 - weight_output_loss: 0.9836 - bag_output_loss: 0.9063 - footwear_output_loss: 0.9185 - pose_output_loss: 0.9254 - emotion_output_loss: 0.9079 - gender_output_acc: 0.5952 - image_quality_output_acc: 0.5534 - age_output_acc: 0.3982 - weight_output_acc: 0.6334 - bag_output_acc: 0.5635 - footwear_output_acc: 0.5821 - pose_output_acc: 0.6175 - emotion_output_acc: 0.7127\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 7.6878 - gender_output_loss: 0.6575 - image_quality_output_loss: 0.9131 - age_output_loss: 1.4207 - weight_output_loss: 0.9834 - bag_output_loss: 0.9059 - footwear_output_loss: 0.9186 - pose_output_loss: 0.9262 - emotion_output_loss: 0.9076 - gender_output_acc: 0.5956 - image_quality_output_acc: 0.5535 - age_output_acc: 0.3986 - weight_output_acc: 0.6337 - bag_output_acc: 0.5638 - footwear_output_acc: 0.5818 - pose_output_acc: 0.6169 - emotion_output_acc: 0.7128 - val_loss: 7.6730 - val_gender_output_loss: 0.6652 - val_image_quality_output_loss: 0.9117 - val_age_output_loss: 1.4315 - val_weight_output_loss: 0.9816 - val_bag_output_loss: 0.9042 - val_footwear_output_loss: 0.8989 - val_pose_output_loss: 0.9223 - val_emotion_output_loss: 0.9035 - val_gender_output_acc: 0.6013 - val_image_quality_output_acc: 0.5533 - val_age_output_acc: 0.4007 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5651 - val_footwear_output_acc: 0.5956 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.7129\n",
      "Epoch 4/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 7.5988 - gender_output_loss: 0.6344 - image_quality_output_loss: 0.9062 - age_output_loss: 1.4170 - weight_output_loss: 0.9806 - bag_output_loss: 0.8987 - footwear_output_loss: 0.8817 - pose_output_loss: 0.9211 - emotion_output_loss: 0.9029 - gender_output_acc: 0.6376 - image_quality_output_acc: 0.5600 - age_output_acc: 0.4026 - weight_output_acc: 0.6338 - bag_output_acc: 0.5671 - footwear_output_acc: 0.6056 - pose_output_acc: 0.6172 - emotion_output_acc: 0.7128 - val_loss: 8.0461 - val_gender_output_loss: 0.6304 - val_image_quality_output_loss: 0.9508 - val_age_output_loss: 1.4141 - val_weight_output_loss: 0.9779 - val_bag_output_loss: 0.8984 - val_footwear_output_loss: 1.2789 - val_pose_output_loss: 0.9184 - val_emotion_output_loss: 0.9201 - val_gender_output_acc: 0.6414 - val_image_quality_output_acc: 0.5389 - val_age_output_acc: 0.4027 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5646 - val_footwear_output_acc: 0.3792 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.7129\n",
      "Epoch 5/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 7.5252 - gender_output_loss: 0.6165 - image_quality_output_loss: 0.9007 - age_output_loss: 1.4117 - weight_output_loss: 0.9790 - bag_output_loss: 0.8916 - footwear_output_loss: 0.8486 - pose_output_loss: 0.9154 - emotion_output_loss: 0.8996 - gender_output_acc: 0.6516 - image_quality_output_acc: 0.5672 - age_output_acc: 0.3996 - weight_output_acc: 0.6338 - bag_output_acc: 0.5730 - footwear_output_acc: 0.6251 - pose_output_acc: 0.6174 - emotion_output_acc: 0.7131 - val_loss: 8.4945 - val_gender_output_loss: 0.7361 - val_image_quality_output_loss: 0.9247 - val_age_output_loss: 1.4238 - val_weight_output_loss: 0.9841 - val_bag_output_loss: 0.8901 - val_footwear_output_loss: 1.6310 - val_pose_output_loss: 0.9314 - val_emotion_output_loss: 0.9077 - val_gender_output_acc: 0.4904 - val_image_quality_output_acc: 0.5757 - val_age_output_acc: 0.4011 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5770 - val_footwear_output_acc: 0.3686 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.7129\n",
      "Epoch 6/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 7.4547 - gender_output_loss: 0.5883 - image_quality_output_loss: 0.8976 - age_output_loss: 1.4082 - weight_output_loss: 0.9750 - bag_output_loss: 0.8766 - footwear_output_loss: 0.8262 - pose_output_loss: 0.9089 - emotion_output_loss: 0.9011 - gender_output_acc: 0.6844 - image_quality_output_acc: 0.5619 - age_output_acc: 0.4007 - weight_output_acc: 0.6338 - bag_output_acc: 0.5860 - footwear_output_acc: 0.6391 - pose_output_acc: 0.6172 - emotion_output_acc: 0.7128 - val_loss: 8.1476 - val_gender_output_loss: 0.7372 - val_image_quality_output_loss: 0.8900 - val_age_output_loss: 1.4282 - val_weight_output_loss: 0.9828 - val_bag_output_loss: 0.9240 - val_footwear_output_loss: 1.2779 - val_pose_output_loss: 0.9246 - val_emotion_output_loss: 0.9044 - val_gender_output_acc: 0.5173 - val_image_quality_output_acc: 0.5674 - val_age_output_acc: 0.4009 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5176 - val_footwear_output_acc: 0.3836 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.7129\n",
      "Epoch 7/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 7.3660 - gender_output_loss: 0.5454 - image_quality_output_loss: 0.8973 - age_output_loss: 1.4043 - weight_output_loss: 0.9733 - bag_output_loss: 0.8660 - footwear_output_loss: 0.8065 - pose_output_loss: 0.8936 - emotion_output_loss: 0.8957 - gender_output_acc: 0.7202 - image_quality_output_acc: 0.5648 - age_output_acc: 0.4018 - weight_output_acc: 0.6336 - bag_output_acc: 0.6022 - footwear_output_acc: 0.6449 - pose_output_acc: 0.6166 - emotion_output_acc: 0.7128 - val_loss: 9.3400 - val_gender_output_loss: 0.5764 - val_image_quality_output_loss: 0.9716 - val_age_output_loss: 1.4505 - val_weight_output_loss: 1.0200 - val_bag_output_loss: 1.0227 - val_footwear_output_loss: 2.3759 - val_pose_output_loss: 0.9125 - val_emotion_output_loss: 0.9209 - val_gender_output_acc: 0.6911 - val_image_quality_output_acc: 0.5628 - val_age_output_acc: 0.3710 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5676 - val_footwear_output_acc: 0.3743 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.7129\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 41s 113ms/step - loss: 7.2852 - gender_output_loss: 0.5125 - image_quality_output_loss: 0.8956 - age_output_loss: 1.4018 - weight_output_loss: 0.9717 - bag_output_loss: 0.8602 - footwear_output_loss: 0.7994 - pose_output_loss: 0.8543 - emotion_output_loss: 0.8927 - gender_output_acc: 0.7474 - image_quality_output_acc: 0.5687 - age_output_acc: 0.4002 - weight_output_acc: 0.6332 - bag_output_acc: 0.6048 - footwear_output_acc: 0.6508 - pose_output_acc: 0.6247 - emotion_output_acc: 0.7128 - val_loss: 7.6753 - val_gender_output_loss: 0.7188 - val_image_quality_output_loss: 0.9238 - val_age_output_loss: 1.4132 - val_weight_output_loss: 0.9678 - val_bag_output_loss: 0.8962 - val_footwear_output_loss: 0.9185 - val_pose_output_loss: 0.8352 - val_emotion_output_loss: 0.8965 - val_gender_output_acc: 0.5692 - val_image_quality_output_acc: 0.5547 - val_age_output_acc: 0.4015 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5653 - val_footwear_output_acc: 0.5595 - val_pose_output_acc: 0.6510 - val_emotion_output_acc: 0.7129\n",
      "Epoch 9/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 7.1515 - gender_output_loss: 0.4814 - image_quality_output_loss: 0.8899 - age_output_loss: 1.3972 - weight_output_loss: 0.9704 - bag_output_loss: 0.8568 - footwear_output_loss: 0.7831 - pose_output_loss: 0.7708 - emotion_output_loss: 0.8890 - gender_output_acc: 0.7693 - image_quality_output_acc: 0.5707 - age_output_acc: 0.4030 - weight_output_acc: 0.6339 - bag_output_acc: 0.6063 - footwear_output_acc: 0.6593 - pose_output_acc: 0.6627 - emotion_output_acc: 0.7128 - val_loss: 7.3827 - val_gender_output_loss: 0.5854 - val_image_quality_output_loss: 0.8876 - val_age_output_loss: 1.4165 - val_weight_output_loss: 0.9760 - val_bag_output_loss: 0.8830 - val_footwear_output_loss: 0.8189 - val_pose_output_loss: 0.8042 - val_emotion_output_loss: 0.8911 - val_gender_output_acc: 0.6803 - val_image_quality_output_acc: 0.5681 - val_age_output_acc: 0.4012 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5868 - val_footwear_output_acc: 0.6285 - val_pose_output_acc: 0.6513 - val_emotion_output_acc: 0.7129\n",
      "Epoch 10/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 7.0059 - gender_output_loss: 0.4415 - image_quality_output_loss: 0.8883 - age_output_loss: 1.3924 - weight_output_loss: 0.9689 - bag_output_loss: 0.8497 - footwear_output_loss: 0.7724 - pose_output_loss: 0.6814 - emotion_output_loss: 0.8836 - gender_output_acc: 0.7944 - image_quality_output_acc: 0.5754 - age_output_acc: 0.4010 - weight_output_acc: 0.6337 - bag_output_acc: 0.6126 - footwear_output_acc: 0.6615 - pose_output_acc: 0.7051 - emotion_output_acc: 0.7129 - val_loss: 9.4598 - val_gender_output_loss: 0.5250 - val_image_quality_output_loss: 0.8918 - val_age_output_loss: 1.4117 - val_weight_output_loss: 0.9786 - val_bag_output_loss: 0.9101 - val_footwear_output_loss: 2.8200 - val_pose_output_loss: 0.9010 - val_emotion_output_loss: 0.8853 - val_gender_output_acc: 0.7516 - val_image_quality_output_acc: 0.5731 - val_age_output_acc: 0.4030 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5688 - val_footwear_output_acc: 0.3684 - val_pose_output_acc: 0.5801 - val_emotion_output_acc: 0.7129\n",
      "Epoch 11/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 6.8927 - gender_output_loss: 0.4122 - image_quality_output_loss: 0.8845 - age_output_loss: 1.3874 - weight_output_loss: 0.9630 - bag_output_loss: 0.8452 - footwear_output_loss: 0.7662 - pose_output_loss: 0.6145 - emotion_output_loss: 0.8756 - gender_output_acc: 0.8140 - image_quality_output_acc: 0.5724 - age_output_acc: 0.4011 - weight_output_acc: 0.6338 - bag_output_acc: 0.6194 - footwear_output_acc: 0.6674 - pose_output_acc: 0.7442 - emotion_output_acc: 0.7128 - val_loss: 7.4091 - val_gender_output_loss: 0.4089 - val_image_quality_output_loss: 0.8790 - val_age_output_loss: 1.3886 - val_weight_output_loss: 0.9672 - val_bag_output_loss: 0.8882 - val_footwear_output_loss: 1.0022 - val_pose_output_loss: 0.8392 - val_emotion_output_loss: 0.8838 - val_gender_output_acc: 0.8053 - val_image_quality_output_acc: 0.5796 - val_age_output_acc: 0.4022 - val_weight_output_acc: 0.6338 - val_bag_output_acc: 0.5885 - val_footwear_output_acc: 0.5628 - val_pose_output_acc: 0.6305 - val_emotion_output_acc: 0.7129\n",
      "Epoch 12/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 6.7842 - gender_output_loss: 0.3742 - image_quality_output_loss: 0.8822 - age_output_loss: 1.3838 - weight_output_loss: 0.9622 - bag_output_loss: 0.8412 - footwear_output_loss: 0.7551 - pose_output_loss: 0.5517 - emotion_output_loss: 0.8723 - gender_output_acc: 0.8371 - image_quality_output_acc: 0.5733 - age_output_acc: 0.4035 - weight_output_acc: 0.6332 - bag_output_acc: 0.6227 - footwear_output_acc: 0.6734 - pose_output_acc: 0.7722 - emotion_output_acc: 0.7128 - val_loss: 6.9297 - val_gender_output_loss: 0.4694 - val_image_quality_output_loss: 0.8758 - val_age_output_loss: 1.3760 - val_weight_output_loss: 0.9542 - val_bag_output_loss: 0.8431 - val_footwear_output_loss: 0.7169 - val_pose_output_loss: 0.6537 - val_emotion_output_loss: 0.8717 - val_gender_output_acc: 0.7570 - val_image_quality_output_acc: 0.5788 - val_age_output_acc: 0.4036 - val_weight_output_acc: 0.6337 - val_bag_output_acc: 0.6110 - val_footwear_output_acc: 0.6905 - val_pose_output_acc: 0.7024 - val_emotion_output_acc: 0.7129\n",
      "Epoch 13/100\n",
      "360/360 [==============================] - 41s 114ms/step - loss: 6.6927 - gender_output_loss: 0.3495 - image_quality_output_loss: 0.8796 - age_output_loss: 1.3768 - weight_output_loss: 0.9598 - bag_output_loss: 0.8330 - footwear_output_loss: 0.7497 - pose_output_loss: 0.5009 - emotion_output_loss: 0.8649 - gender_output_acc: 0.8460 - image_quality_output_acc: 0.5766 - age_output_acc: 0.4010 - weight_output_acc: 0.6340 - bag_output_acc: 0.6321 - footwear_output_acc: 0.6783 - pose_output_acc: 0.8013 - emotion_output_acc: 0.7129 - val_loss: 6.7093 - val_gender_output_loss: 0.3075 - val_image_quality_output_loss: 0.8581 - val_age_output_loss: 1.3702 - val_weight_output_loss: 0.9506 - val_bag_output_loss: 0.8258 - val_footwear_output_loss: 0.8154 - val_pose_output_loss: 0.5352 - val_emotion_output_loss: 0.8586 - val_gender_output_acc: 0.8697 - val_image_quality_output_acc: 0.5811 - val_age_output_acc: 0.4052 - val_weight_output_acc: 0.6337 - val_bag_output_acc: 0.6305 - val_footwear_output_acc: 0.6304 - val_pose_output_acc: 0.7801 - val_emotion_output_acc: 0.7129\n",
      "Epoch 14/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 6.5908 - gender_output_loss: 0.3141 - image_quality_output_loss: 0.8705 - age_output_loss: 1.3704 - weight_output_loss: 0.9507 - bag_output_loss: 0.8287 - footwear_output_loss: 0.7417 - pose_output_loss: 0.4579 - emotion_output_loss: 0.8610 - gender_output_acc: 0.8691 - image_quality_output_acc: 0.5821 - age_output_acc: 0.4049 - weight_output_acc: 0.6338 - bag_output_acc: 0.6325 - footwear_output_acc: 0.6813 - pose_output_acc: 0.8184 - emotion_output_acc: 0.7129 - val_loss: 6.6430 - val_gender_output_loss: 0.3045 - val_image_quality_output_loss: 0.9069 - val_age_output_loss: 1.3597 - val_weight_output_loss: 0.9423 - val_bag_output_loss: 0.8170 - val_footwear_output_loss: 0.8240 - val_pose_output_loss: 0.4338 - val_emotion_output_loss: 0.8510 - val_gender_output_acc: 0.8723 - val_image_quality_output_acc: 0.5720 - val_age_output_acc: 0.4094 - val_weight_output_acc: 0.6344 - val_bag_output_acc: 0.6477 - val_footwear_output_acc: 0.6149 - val_pose_output_acc: 0.8411 - val_emotion_output_acc: 0.7129\n",
      "Epoch 15/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 6.4890 - gender_output_loss: 0.2838 - image_quality_output_loss: 0.8674 - age_output_loss: 1.3555 - weight_output_loss: 0.9437 - bag_output_loss: 0.8200 - footwear_output_loss: 0.7290 - pose_output_loss: 0.4227 - emotion_output_loss: 0.8543 - gender_output_acc: 0.8841 - image_quality_output_acc: 0.5783 - age_output_acc: 0.4118 - weight_output_acc: 0.6335 - bag_output_acc: 0.6387 - footwear_output_acc: 0.6855 - pose_output_acc: 0.8356 - emotion_output_acc: 0.7128 - val_loss: 6.4305 - val_gender_output_loss: 0.3023 - val_image_quality_output_loss: 0.8431 - val_age_output_loss: 1.3342 - val_weight_output_loss: 0.9334 - val_bag_output_loss: 0.8053 - val_footwear_output_loss: 0.7363 - val_pose_output_loss: 0.4058 - val_emotion_output_loss: 0.8485 - val_gender_output_acc: 0.8674 - val_image_quality_output_acc: 0.5943 - val_age_output_acc: 0.4123 - val_weight_output_acc: 0.6387 - val_bag_output_acc: 0.6501 - val_footwear_output_acc: 0.6682 - val_pose_output_acc: 0.8461 - val_emotion_output_acc: 0.7129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 6.4164 - gender_output_loss: 0.2670 - image_quality_output_loss: 0.8595 - age_output_loss: 1.3454 - weight_output_loss: 0.9358 - bag_output_loss: 0.8182 - footwear_output_loss: 0.7138 - pose_output_loss: 0.3947 - emotion_output_loss: 0.8497 - gender_output_acc: 0.8898 - image_quality_output_acc: 0.5884 - age_output_acc: 0.4102 - weight_output_acc: 0.6384 - bag_output_acc: 0.6408 - footwear_output_acc: 0.6923 - pose_output_acc: 0.8483 - emotion_output_acc: 0.7130 - val_loss: 6.5376 - val_gender_output_loss: 0.2563 - val_image_quality_output_loss: 0.8442 - val_age_output_loss: 1.3359 - val_weight_output_loss: 0.9375 - val_bag_output_loss: 0.8125 - val_footwear_output_loss: 0.7051 - val_pose_output_loss: 0.5461 - val_emotion_output_loss: 0.8582 - val_gender_output_acc: 0.8944 - val_image_quality_output_acc: 0.5931 - val_age_output_acc: 0.4174 - val_weight_output_acc: 0.6385 - val_bag_output_acc: 0.6359 - val_footwear_output_acc: 0.6924 - val_pose_output_acc: 0.7740 - val_emotion_output_acc: 0.7129\n",
      "Epoch 17/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 6.3143 - gender_output_loss: 0.2418 - image_quality_output_loss: 0.8549 - age_output_loss: 1.3274 - weight_output_loss: 0.9278 - bag_output_loss: 0.8048 - footwear_output_loss: 0.6992 - pose_output_loss: 0.3623 - emotion_output_loss: 0.8443 - gender_output_acc: 0.9030 - image_quality_output_acc: 0.5875 - age_output_acc: 0.4211 - weight_output_acc: 0.6389 - bag_output_acc: 0.6527 - footwear_output_acc: 0.7001 - pose_output_acc: 0.8629 - emotion_output_acc: 0.7127 - val_loss: 6.3504 - val_gender_output_loss: 0.1904 - val_image_quality_output_loss: 0.8576 - val_age_output_loss: 1.3020 - val_weight_output_loss: 0.9136 - val_bag_output_loss: 0.7934 - val_footwear_output_loss: 0.8132 - val_pose_output_loss: 0.3673 - val_emotion_output_loss: 0.8499 - val_gender_output_acc: 0.9292 - val_image_quality_output_acc: 0.5939 - val_age_output_acc: 0.4268 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.6554 - val_footwear_output_acc: 0.6224 - val_pose_output_acc: 0.8628 - val_emotion_output_acc: 0.7129\n",
      "Epoch 18/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 6.1980 - gender_output_loss: 0.2116 - image_quality_output_loss: 0.8449 - age_output_loss: 1.3043 - weight_output_loss: 0.9103 - bag_output_loss: 0.7976 - footwear_output_loss: 0.6855 - pose_output_loss: 0.3269 - emotion_output_loss: 0.8432 - gender_output_acc: 0.9190 - image_quality_output_acc: 0.5937 - age_output_acc: 0.4253 - weight_output_acc: 0.6447 - bag_output_acc: 0.6550 - footwear_output_acc: 0.7081 - pose_output_acc: 0.8757 - emotion_output_acc: 0.7128 - val_loss: 6.4995 - val_gender_output_loss: 0.2709 - val_image_quality_output_loss: 0.8415 - val_age_output_loss: 1.4361 - val_weight_output_loss: 1.0612 - val_bag_output_loss: 0.7922 - val_footwear_output_loss: 0.6560 - val_pose_output_loss: 0.3173 - val_emotion_output_loss: 0.8379 - val_gender_output_acc: 0.8826 - val_image_quality_output_acc: 0.5901 - val_age_output_acc: 0.3675 - val_weight_output_acc: 0.5300 - val_bag_output_acc: 0.6518 - val_footwear_output_acc: 0.7135 - val_pose_output_acc: 0.8821 - val_emotion_output_acc: 0.7129\n",
      "Epoch 19/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 6.0861 - gender_output_loss: 0.1912 - image_quality_output_loss: 0.8310 - age_output_loss: 1.2808 - weight_output_loss: 0.8976 - bag_output_loss: 0.7872 - footwear_output_loss: 0.6660 - pose_output_loss: 0.2973 - emotion_output_loss: 0.8378 - gender_output_acc: 0.9257 - image_quality_output_acc: 0.5985 - age_output_acc: 0.4325 - weight_output_acc: 0.6459 - bag_output_acc: 0.6629 - footwear_output_acc: 0.7137 - pose_output_acc: 0.8887 - emotion_output_acc: 0.7127 - val_loss: 6.1000 - val_gender_output_loss: 0.1435 - val_image_quality_output_loss: 0.8680 - val_age_output_loss: 1.2299 - val_weight_output_loss: 0.8682 - val_bag_output_loss: 0.7744 - val_footwear_output_loss: 0.6123 - val_pose_output_loss: 0.4335 - val_emotion_output_loss: 0.8608 - val_gender_output_acc: 0.9459 - val_image_quality_output_acc: 0.5830 - val_age_output_acc: 0.4493 - val_weight_output_acc: 0.6545 - val_bag_output_acc: 0.6627 - val_footwear_output_acc: 0.7349 - val_pose_output_acc: 0.8240 - val_emotion_output_acc: 0.7129\n",
      "Epoch 20/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 5.9499 - gender_output_loss: 0.1636 - image_quality_output_loss: 0.8199 - age_output_loss: 1.2556 - weight_output_loss: 0.8788 - bag_output_loss: 0.7766 - footwear_output_loss: 0.6404 - pose_output_loss: 0.2640 - emotion_output_loss: 0.8297 - gender_output_acc: 0.9365 - image_quality_output_acc: 0.6084 - age_output_acc: 0.4422 - weight_output_acc: 0.6522 - bag_output_acc: 0.6674 - footwear_output_acc: 0.7236 - pose_output_acc: 0.9010 - emotion_output_acc: 0.7128 - val_loss: 5.9521 - val_gender_output_loss: 0.1560 - val_image_quality_output_loss: 0.8672 - val_age_output_loss: 1.2213 - val_weight_output_loss: 0.8584 - val_bag_output_loss: 0.7772 - val_footwear_output_loss: 0.5943 - val_pose_output_loss: 0.3177 - val_emotion_output_loss: 0.8259 - val_gender_output_acc: 0.9392 - val_image_quality_output_acc: 0.5841 - val_age_output_acc: 0.4601 - val_weight_output_acc: 0.6721 - val_bag_output_acc: 0.6628 - val_footwear_output_acc: 0.7409 - val_pose_output_acc: 0.8793 - val_emotion_output_acc: 0.7129\n",
      "Epoch 21/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 5.8112 - gender_output_loss: 0.1519 - image_quality_output_loss: 0.8030 - age_output_loss: 1.2200 - weight_output_loss: 0.8569 - bag_output_loss: 0.7616 - footwear_output_loss: 0.6078 - pose_output_loss: 0.2384 - emotion_output_loss: 0.8255 - gender_output_acc: 0.9438 - image_quality_output_acc: 0.6215 - age_output_acc: 0.4559 - weight_output_acc: 0.6618 - bag_output_acc: 0.6776 - footwear_output_acc: 0.7396 - pose_output_acc: 0.9120 - emotion_output_acc: 0.7126 - val_loss: 6.2820 - val_gender_output_loss: 0.3609 - val_image_quality_output_loss: 0.8163 - val_age_output_loss: 1.2105 - val_weight_output_loss: 0.8777 - val_bag_output_loss: 0.7499 - val_footwear_output_loss: 0.8205 - val_pose_output_loss: 0.2664 - val_emotion_output_loss: 0.8197 - val_gender_output_acc: 0.8379 - val_image_quality_output_acc: 0.6035 - val_age_output_acc: 0.4658 - val_weight_output_acc: 0.6635 - val_bag_output_acc: 0.6995 - val_footwear_output_acc: 0.6347 - val_pose_output_acc: 0.8953 - val_emotion_output_acc: 0.7129\n",
      "Epoch 22/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 5.6856 - gender_output_loss: 0.1384 - image_quality_output_loss: 0.7811 - age_output_loss: 1.1854 - weight_output_loss: 0.8403 - bag_output_loss: 0.7460 - footwear_output_loss: 0.5860 - pose_output_loss: 0.2186 - emotion_output_loss: 0.8189 - gender_output_acc: 0.9464 - image_quality_output_acc: 0.6189 - age_output_acc: 0.4713 - weight_output_acc: 0.6719 - bag_output_acc: 0.6839 - footwear_output_acc: 0.7444 - pose_output_acc: 0.9157 - emotion_output_acc: 0.7131 - val_loss: 5.6881 - val_gender_output_loss: 0.1248 - val_image_quality_output_loss: 0.7639 - val_age_output_loss: 1.2730 - val_weight_output_loss: 0.8864 - val_bag_output_loss: 0.7262 - val_footwear_output_loss: 0.5482 - val_pose_output_loss: 0.1760 - val_emotion_output_loss: 0.8067 - val_gender_output_acc: 0.9516 - val_image_quality_output_acc: 0.6371 - val_age_output_acc: 0.4420 - val_weight_output_acc: 0.6437 - val_bag_output_acc: 0.6964 - val_footwear_output_acc: 0.7582 - val_pose_output_acc: 0.9333 - val_emotion_output_acc: 0.7128\n",
      "Epoch 23/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 5.5391 - gender_output_loss: 0.1249 - image_quality_output_loss: 0.7577 - age_output_loss: 1.1541 - weight_output_loss: 0.8142 - bag_output_loss: 0.7312 - footwear_output_loss: 0.5590 - pose_output_loss: 0.1931 - emotion_output_loss: 0.8098 - gender_output_acc: 0.9530 - image_quality_output_acc: 0.6424 - age_output_acc: 0.4805 - weight_output_acc: 0.6796 - bag_output_acc: 0.6993 - footwear_output_acc: 0.7606 - pose_output_acc: 0.9264 - emotion_output_acc: 0.7131 - val_loss: 5.4825 - val_gender_output_loss: 0.1556 - val_image_quality_output_loss: 0.7030 - val_age_output_loss: 1.2165 - val_weight_output_loss: 0.8447 - val_bag_output_loss: 0.6865 - val_footwear_output_loss: 0.5011 - val_pose_output_loss: 0.1658 - val_emotion_output_loss: 0.7995 - val_gender_output_acc: 0.9351 - val_image_quality_output_acc: 0.6752 - val_age_output_acc: 0.4635 - val_weight_output_acc: 0.6707 - val_bag_output_acc: 0.7249 - val_footwear_output_acc: 0.7784 - val_pose_output_acc: 0.9424 - val_emotion_output_acc: 0.7132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 5.3962 - gender_output_loss: 0.1183 - image_quality_output_loss: 0.7257 - age_output_loss: 1.1193 - weight_output_loss: 0.7912 - bag_output_loss: 0.7081 - footwear_output_loss: 0.5312 - pose_output_loss: 0.1743 - emotion_output_loss: 0.8085 - gender_output_acc: 0.9547 - image_quality_output_acc: 0.6526 - age_output_acc: 0.4943 - weight_output_acc: 0.6901 - bag_output_acc: 0.7097 - footwear_output_acc: 0.7687 - pose_output_acc: 0.9367 - emotion_output_acc: 0.7128 - val_loss: 7.7804 - val_gender_output_loss: 1.2794 - val_image_quality_output_loss: 0.6998 - val_age_output_loss: 1.1555 - val_weight_output_loss: 0.8786 - val_bag_output_loss: 1.0624 - val_footwear_output_loss: 1.0933 - val_pose_output_loss: 0.3470 - val_emotion_output_loss: 0.8318 - val_gender_output_acc: 0.6623 - val_image_quality_output_acc: 0.6735 - val_age_output_acc: 0.4863 - val_weight_output_acc: 0.6650 - val_bag_output_acc: 0.5990 - val_footwear_output_acc: 0.5895 - val_pose_output_acc: 0.8629 - val_emotion_output_acc: 0.7131\n",
      "Epoch 25/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 5.2680 - gender_output_loss: 0.1084 - image_quality_output_loss: 0.6907 - age_output_loss: 1.0921 - weight_output_loss: 0.7823 - bag_output_loss: 0.6853 - footwear_output_loss: 0.5057 - pose_output_loss: 0.1565 - emotion_output_loss: 0.8041 - gender_output_acc: 0.9602 - image_quality_output_acc: 0.6742 - age_output_acc: 0.5051 - weight_output_acc: 0.6922 - bag_output_acc: 0.7229 - footwear_output_acc: 0.7773 - pose_output_acc: 0.9418 - emotion_output_acc: 0.7135 - val_loss: 5.6405 - val_gender_output_loss: 0.0657 - val_image_quality_output_loss: 0.6414 - val_age_output_loss: 1.1119 - val_weight_output_loss: 0.8100 - val_bag_output_loss: 0.8652 - val_footwear_output_loss: 0.6078 - val_pose_output_loss: 0.2896 - val_emotion_output_loss: 0.7930 - val_gender_output_acc: 0.9777 - val_image_quality_output_acc: 0.7128 - val_age_output_acc: 0.5040 - val_weight_output_acc: 0.6901 - val_bag_output_acc: 0.5986 - val_footwear_output_acc: 0.7151 - val_pose_output_acc: 0.8839 - val_emotion_output_acc: 0.7128\n",
      "Epoch 26/100\n",
      "359/360 [============================>.] - ETA: 0s - loss: 5.1164 - gender_output_loss: 0.0992 - image_quality_output_loss: 0.6476 - age_output_loss: 1.0546 - weight_output_loss: 0.7666 - bag_output_loss: 0.6668 - footwear_output_loss: 0.4845 - pose_output_loss: 0.1375 - emotion_output_loss: 0.7942 - gender_output_acc: 0.9624 - image_quality_output_acc: 0.6982 - age_output_acc: 0.5213 - weight_output_acc: 0.6993 - bag_output_acc: 0.7308 - footwear_output_acc: 0.7891 - pose_output_acc: 0.9493 - emotion_output_acc: 0.7133Epoch 26/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 5.1176 - gender_output_loss: 0.0992 - image_quality_output_loss: 0.6480 - age_output_loss: 1.0551 - weight_output_loss: 0.7664 - bag_output_loss: 0.6669 - footwear_output_loss: 0.4844 - pose_output_loss: 0.1380 - emotion_output_loss: 0.7942 - gender_output_acc: 0.9623 - image_quality_output_acc: 0.6978 - age_output_acc: 0.5213 - weight_output_acc: 0.6993 - bag_output_acc: 0.7306 - footwear_output_acc: 0.7890 - pose_output_acc: 0.9493 - emotion_output_acc: 0.7132 - val_loss: 5.1363 - val_gender_output_loss: 0.0636 - val_image_quality_output_loss: 0.8614 - val_age_output_loss: 1.0582 - val_weight_output_loss: 0.7499 - val_bag_output_loss: 0.5927 - val_footwear_output_loss: 0.4305 - val_pose_output_loss: 0.1207 - val_emotion_output_loss: 0.7814 - val_gender_output_acc: 0.9769 - val_image_quality_output_acc: 0.5389 - val_age_output_acc: 0.5235 - val_weight_output_acc: 0.7043 - val_bag_output_acc: 0.7714 - val_footwear_output_acc: 0.8072 - val_pose_output_acc: 0.9551 - val_emotion_output_acc: 0.7131\n",
      "Epoch 27/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 5.0160 - gender_output_loss: 0.0943 - image_quality_output_loss: 0.6126 - age_output_loss: 1.0411 - weight_output_loss: 0.7555 - bag_output_loss: 0.6262 - footwear_output_loss: 0.4668 - pose_output_loss: 0.1416 - emotion_output_loss: 0.7906 - gender_output_acc: 0.9649 - image_quality_output_acc: 0.7237 - age_output_acc: 0.5306 - weight_output_acc: 0.7049 - bag_output_acc: 0.7565 - footwear_output_acc: 0.7923 - pose_output_acc: 0.9450 - emotion_output_acc: 0.7146 - val_loss: 6.0189 - val_gender_output_loss: 0.2924 - val_image_quality_output_loss: 0.5514 - val_age_output_loss: 1.0987 - val_weight_output_loss: 0.7328 - val_bag_output_loss: 0.6013 - val_footwear_output_loss: 1.3351 - val_pose_output_loss: 0.1303 - val_emotion_output_loss: 0.7768 - val_gender_output_acc: 0.8874 - val_image_quality_output_acc: 0.7567 - val_age_output_acc: 0.5070 - val_weight_output_acc: 0.7088 - val_bag_output_acc: 0.7707 - val_footwear_output_acc: 0.5396 - val_pose_output_acc: 0.9515 - val_emotion_output_acc: 0.7142\n",
      "Epoch 28/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 4.9015 - gender_output_loss: 0.0831 - image_quality_output_loss: 0.5718 - age_output_loss: 1.0208 - weight_output_loss: 0.7437 - bag_output_loss: 0.5918 - footwear_output_loss: 0.4544 - pose_output_loss: 0.1423 - emotion_output_loss: 0.7847 - gender_output_acc: 0.9694 - image_quality_output_acc: 0.7422 - age_output_acc: 0.5354 - weight_output_acc: 0.7049 - bag_output_acc: 0.7690 - footwear_output_acc: 0.7942 - pose_output_acc: 0.9475 - emotion_output_acc: 0.7143 - val_loss: 4.6682 - val_gender_output_loss: 0.1010 - val_image_quality_output_loss: 0.5010 - val_age_output_loss: 1.0287 - val_weight_output_loss: 0.7307 - val_bag_output_loss: 0.5175 - val_footwear_output_loss: 0.4257 - val_pose_output_loss: 0.0747 - val_emotion_output_loss: 0.7677 - val_gender_output_acc: 0.9602 - val_image_quality_output_acc: 0.7985 - val_age_output_acc: 0.5418 - val_weight_output_acc: 0.7114 - val_bag_output_acc: 0.8094 - val_footwear_output_acc: 0.8091 - val_pose_output_acc: 0.9764 - val_emotion_output_acc: 0.7141\n",
      "Epoch 29/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 4.7867 - gender_output_loss: 0.0861 - image_quality_output_loss: 0.5314 - age_output_loss: 0.9969 - weight_output_loss: 0.7364 - bag_output_loss: 0.5495 - footwear_output_loss: 0.4499 - pose_output_loss: 0.1303 - emotion_output_loss: 0.7758 - gender_output_acc: 0.9692 - image_quality_output_acc: 0.7624 - age_output_acc: 0.5534 - weight_output_acc: 0.7043 - bag_output_acc: 0.7919 - footwear_output_acc: 0.7961 - pose_output_acc: 0.9523 - emotion_output_acc: 0.7142 - val_loss: 5.4945 - val_gender_output_loss: 0.2436 - val_image_quality_output_loss: 0.8645 - val_age_output_loss: 1.2746 - val_weight_output_loss: 0.7847 - val_bag_output_loss: 0.4854 - val_footwear_output_loss: 0.4519 - val_pose_output_loss: 0.0687 - val_emotion_output_loss: 0.7788 - val_gender_output_acc: 0.9129 - val_image_quality_output_acc: 0.5933 - val_age_output_acc: 0.4252 - val_weight_output_acc: 0.6968 - val_bag_output_acc: 0.8216 - val_footwear_output_acc: 0.7914 - val_pose_output_acc: 0.9759 - val_emotion_output_acc: 0.7125\n",
      "Epoch 30/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 4.6834 - gender_output_loss: 0.0859 - image_quality_output_loss: 0.4946 - age_output_loss: 0.9761 - weight_output_loss: 0.7255 - bag_output_loss: 0.5173 - footwear_output_loss: 0.4355 - pose_output_loss: 0.1279 - emotion_output_loss: 0.7700 - gender_output_acc: 0.9669 - image_quality_output_acc: 0.7866 - age_output_acc: 0.5650 - weight_output_acc: 0.7131 - bag_output_acc: 0.8029 - footwear_output_acc: 0.8046 - pose_output_acc: 0.9539 - emotion_output_acc: 0.7152 - val_loss: 4.8945 - val_gender_output_loss: 0.0915 - val_image_quality_output_loss: 0.6194 - val_age_output_loss: 0.9530 - val_weight_output_loss: 0.7046 - val_bag_output_loss: 0.4434 - val_footwear_output_loss: 0.5358 - val_pose_output_loss: 0.2107 - val_emotion_output_loss: 0.7739 - val_gender_output_acc: 0.9643 - val_image_quality_output_acc: 0.7039 - val_age_output_acc: 0.5741 - val_weight_output_acc: 0.7234 - val_bag_output_acc: 0.8380 - val_footwear_output_acc: 0.7639 - val_pose_output_acc: 0.9190 - val_emotion_output_acc: 0.7139\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 40s 111ms/step - loss: 4.5968 - gender_output_loss: 0.0859 - image_quality_output_loss: 0.4538 - age_output_loss: 0.9582 - weight_output_loss: 0.7208 - bag_output_loss: 0.4934 - footwear_output_loss: 0.4299 - pose_output_loss: 0.1189 - emotion_output_loss: 0.7656 - gender_output_acc: 0.9673 - image_quality_output_acc: 0.8036 - age_output_acc: 0.5766 - weight_output_acc: 0.7119 - bag_output_acc: 0.8132 - footwear_output_acc: 0.8034 - pose_output_acc: 0.9562 - emotion_output_acc: 0.7168 - val_loss: 4.8703 - val_gender_output_loss: 0.0805 - val_image_quality_output_loss: 0.7500 - val_age_output_loss: 0.9631 - val_weight_output_loss: 0.6817 - val_bag_output_loss: 0.4344 - val_footwear_output_loss: 0.4539 - val_pose_output_loss: 0.1263 - val_emotion_output_loss: 0.7998 - val_gender_output_acc: 0.9693 - val_image_quality_output_acc: 0.6479 - val_age_output_acc: 0.5761 - val_weight_output_acc: 0.7349 - val_bag_output_acc: 0.8400 - val_footwear_output_acc: 0.7908 - val_pose_output_acc: 0.9530 - val_emotion_output_acc: 0.7128\n",
      "Epoch 32/100\n",
      "360/360 [==============================] - 41s 114ms/step - loss: 4.5095 - gender_output_loss: 0.0806 - image_quality_output_loss: 0.4429 - age_output_loss: 0.9334 - weight_output_loss: 0.7017 - bag_output_loss: 0.4622 - footwear_output_loss: 0.4200 - pose_output_loss: 0.1217 - emotion_output_loss: 0.7583 - gender_output_acc: 0.9667 - image_quality_output_acc: 0.8104 - age_output_acc: 0.5871 - weight_output_acc: 0.7217 - bag_output_acc: 0.8235 - footwear_output_acc: 0.8095 - pose_output_acc: 0.9547 - emotion_output_acc: 0.7144 - val_loss: 5.2525 - val_gender_output_loss: 0.0574 - val_image_quality_output_loss: 1.3893 - val_age_output_loss: 0.8583 - val_weight_output_loss: 0.6652 - val_bag_output_loss: 0.3919 - val_footwear_output_loss: 0.3765 - val_pose_output_loss: 0.1494 - val_emotion_output_loss: 0.7658 - val_gender_output_acc: 0.9786 - val_image_quality_output_acc: 0.3876 - val_age_output_acc: 0.6293 - val_weight_output_acc: 0.7392 - val_bag_output_acc: 0.8570 - val_footwear_output_acc: 0.8246 - val_pose_output_acc: 0.9402 - val_emotion_output_acc: 0.7146\n",
      "Epoch 33/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 4.4305 - gender_output_loss: 0.0862 - image_quality_output_loss: 0.4024 - age_output_loss: 0.9250 - weight_output_loss: 0.6941 - bag_output_loss: 0.4362 - footwear_output_loss: 0.4103 - pose_output_loss: 0.1151 - emotion_output_loss: 0.7549 - gender_output_acc: 0.9668 - image_quality_output_acc: 0.8324 - age_output_acc: 0.5918 - weight_output_acc: 0.7261 - bag_output_acc: 0.8339 - footwear_output_acc: 0.8091 - pose_output_acc: 0.9580 - emotion_output_acc: 0.7168 - val_loss: 6.6178 - val_gender_output_loss: 0.3721 - val_image_quality_output_loss: 1.0573 - val_age_output_loss: 1.2283 - val_weight_output_loss: 0.7640 - val_bag_output_loss: 0.4610 - val_footwear_output_loss: 0.3729 - val_pose_output_loss: 0.9998 - val_emotion_output_loss: 0.7457 - val_gender_output_acc: 0.8590 - val_image_quality_output_acc: 0.4727 - val_age_output_acc: 0.4206 - val_weight_output_acc: 0.7011 - val_bag_output_acc: 0.8296 - val_footwear_output_acc: 0.8296 - val_pose_output_acc: 0.6681 - val_emotion_output_acc: 0.7177\n",
      "Epoch 34/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 4.3393 - gender_output_loss: 0.0713 - image_quality_output_loss: 0.3754 - age_output_loss: 0.8927 - weight_output_loss: 0.6812 - bag_output_loss: 0.4106 - footwear_output_loss: 0.4200 - pose_output_loss: 0.1159 - emotion_output_loss: 0.7480 - gender_output_acc: 0.9717 - image_quality_output_acc: 0.8479 - age_output_acc: 0.6031 - weight_output_acc: 0.7336 - bag_output_acc: 0.8450 - footwear_output_acc: 0.8067 - pose_output_acc: 0.9564 - emotion_output_acc: 0.7200 - val_loss: 4.0700 - val_gender_output_loss: 0.0366 - val_image_quality_output_loss: 0.3504 - val_age_output_loss: 0.7982 - val_weight_output_loss: 0.7131 - val_bag_output_loss: 0.3765 - val_footwear_output_loss: 0.3834 - val_pose_output_loss: 0.0594 - val_emotion_output_loss: 0.7184 - val_gender_output_acc: 0.9863 - val_image_quality_output_acc: 0.8464 - val_age_output_acc: 0.6558 - val_weight_output_acc: 0.7138 - val_bag_output_acc: 0.8573 - val_footwear_output_acc: 0.8231 - val_pose_output_acc: 0.9793 - val_emotion_output_acc: 0.7256\n",
      "Epoch 35/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 4.2902 - gender_output_loss: 0.0762 - image_quality_output_loss: 0.3580 - age_output_loss: 0.8701 - weight_output_loss: 0.6659 - bag_output_loss: 0.4082 - footwear_output_loss: 0.4134 - pose_output_loss: 0.1155 - emotion_output_loss: 0.7412 - gender_output_acc: 0.9726 - image_quality_output_acc: 0.8499 - age_output_acc: 0.6149 - weight_output_acc: 0.7366 - bag_output_acc: 0.8475 - footwear_output_acc: 0.8095 - pose_output_acc: 0.9569 - emotion_output_acc: 0.7202 - val_loss: 4.9685 - val_gender_output_loss: 0.0267 - val_image_quality_output_loss: 0.5897 - val_age_output_loss: 0.8022 - val_weight_output_loss: 0.6324 - val_bag_output_loss: 0.3160 - val_footwear_output_loss: 0.5161 - val_pose_output_loss: 0.7034 - val_emotion_output_loss: 0.7308 - val_gender_output_acc: 0.9906 - val_image_quality_output_acc: 0.7174 - val_age_output_acc: 0.6701 - val_weight_output_acc: 0.7655 - val_bag_output_acc: 0.8812 - val_footwear_output_acc: 0.7707 - val_pose_output_acc: 0.7549 - val_emotion_output_acc: 0.7186\n",
      "Epoch 36/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 4.2568 - gender_output_loss: 0.0844 - image_quality_output_loss: 0.3607 - age_output_loss: 0.8562 - weight_output_loss: 0.6526 - bag_output_loss: 0.3829 - footwear_output_loss: 0.4148 - pose_output_loss: 0.1220 - emotion_output_loss: 0.7238 - gender_output_acc: 0.9674 - image_quality_output_acc: 0.8514 - age_output_acc: 0.6205 - weight_output_acc: 0.7490 - bag_output_acc: 0.8559 - footwear_output_acc: 0.8079 - pose_output_acc: 0.9563 - emotion_output_acc: 0.7318 - val_loss: 3.9592 - val_gender_output_loss: 0.0473 - val_image_quality_output_loss: 0.2710 - val_age_output_loss: 0.7491 - val_weight_output_loss: 0.6316 - val_bag_output_loss: 0.3836 - val_footwear_output_loss: 0.3645 - val_pose_output_loss: 0.1551 - val_emotion_output_loss: 0.6882 - val_gender_output_acc: 0.9830 - val_image_quality_output_acc: 0.8979 - val_age_output_acc: 0.6824 - val_weight_output_acc: 0.7647 - val_bag_output_acc: 0.8573 - val_footwear_output_acc: 0.8331 - val_pose_output_acc: 0.9413 - val_emotion_output_acc: 0.7282\n",
      "Epoch 37/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 4.1612 - gender_output_loss: 0.0796 - image_quality_output_loss: 0.3368 - age_output_loss: 0.8327 - weight_output_loss: 0.6247 - bag_output_loss: 0.3735 - footwear_output_loss: 0.4057 - pose_output_loss: 0.1134 - emotion_output_loss: 0.7192 - gender_output_acc: 0.9700 - image_quality_output_acc: 0.8620 - age_output_acc: 0.6323 - weight_output_acc: 0.7556 - bag_output_acc: 0.8619 - footwear_output_acc: 0.8127 - pose_output_acc: 0.9586 - emotion_output_acc: 0.7305 - val_loss: 4.0235 - val_gender_output_loss: 0.0494 - val_image_quality_output_loss: 0.2294 - val_age_output_loss: 0.8157 - val_weight_output_loss: 0.6300 - val_bag_output_loss: 0.4289 - val_footwear_output_loss: 0.3494 - val_pose_output_loss: 0.1709 - val_emotion_output_loss: 0.6654 - val_gender_output_acc: 0.9801 - val_image_quality_output_acc: 0.9139 - val_age_output_acc: 0.6350 - val_weight_output_acc: 0.7562 - val_bag_output_acc: 0.8419 - val_footwear_output_acc: 0.8372 - val_pose_output_acc: 0.9359 - val_emotion_output_acc: 0.7427\n",
      "Epoch 38/100\n",
      "360/360 [==============================] - 41s 114ms/step - loss: 4.0967 - gender_output_loss: 0.0706 - image_quality_output_loss: 0.3206 - age_output_loss: 0.8115 - weight_output_loss: 0.6080 - bag_output_loss: 0.3738 - footwear_output_loss: 0.4014 - pose_output_loss: 0.1102 - emotion_output_loss: 0.7090 - gender_output_acc: 0.9708 - image_quality_output_acc: 0.8709 - age_output_acc: 0.6484 - weight_output_acc: 0.7609 - bag_output_acc: 0.8605 - footwear_output_acc: 0.8133 - pose_output_acc: 0.9597 - emotion_output_acc: 0.7343 - val_loss: 4.2923 - val_gender_output_loss: 0.0832 - val_image_quality_output_loss: 0.2844 - val_age_output_loss: 0.8784 - val_weight_output_loss: 0.5407 - val_bag_output_loss: 0.6610 - val_footwear_output_loss: 0.3721 - val_pose_output_loss: 0.0836 - val_emotion_output_loss: 0.6889 - val_gender_output_acc: 0.9675 - val_image_quality_output_acc: 0.8949 - val_age_output_acc: 0.6051 - val_weight_output_acc: 0.7989 - val_bag_output_acc: 0.7749 - val_footwear_output_acc: 0.8231 - val_pose_output_acc: 0.9695 - val_emotion_output_acc: 0.7546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 4.0511 - gender_output_loss: 0.0786 - image_quality_output_loss: 0.3136 - age_output_loss: 0.7895 - weight_output_loss: 0.5806 - bag_output_loss: 0.3706 - footwear_output_loss: 0.4025 - pose_output_loss: 0.1177 - emotion_output_loss: 0.6910 - gender_output_acc: 0.9688 - image_quality_output_acc: 0.8745 - age_output_acc: 0.6615 - weight_output_acc: 0.7720 - bag_output_acc: 0.8577 - footwear_output_acc: 0.8160 - pose_output_acc: 0.9556 - emotion_output_acc: 0.7433 - val_loss: 8.1480 - val_gender_output_loss: 0.0299 - val_image_quality_output_loss: 0.4300 - val_age_output_loss: 0.9415 - val_weight_output_loss: 0.9328 - val_bag_output_loss: 3.5348 - val_footwear_output_loss: 0.5725 - val_pose_output_loss: 0.2177 - val_emotion_output_loss: 0.7716 - val_gender_output_acc: 0.9905 - val_image_quality_output_acc: 0.8105 - val_age_output_acc: 0.5732 - val_weight_output_acc: 0.6456 - val_bag_output_acc: 0.3453 - val_footwear_output_acc: 0.7608 - val_pose_output_acc: 0.9176 - val_emotion_output_acc: 0.7229\n",
      "Epoch 40/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.9911 - gender_output_loss: 0.0660 - image_quality_output_loss: 0.3075 - age_output_loss: 0.7765 - weight_output_loss: 0.5648 - bag_output_loss: 0.3661 - footwear_output_loss: 0.3905 - pose_output_loss: 0.1194 - emotion_output_loss: 0.6766 - gender_output_acc: 0.9747 - image_quality_output_acc: 0.8770 - age_output_acc: 0.6657 - weight_output_acc: 0.7839 - bag_output_acc: 0.8632 - footwear_output_acc: 0.8197 - pose_output_acc: 0.9563 - emotion_output_acc: 0.7508 - val_loss: 5.1134 - val_gender_output_loss: 0.2602 - val_image_quality_output_loss: 0.7342 - val_age_output_loss: 0.6166 - val_weight_output_loss: 0.4863 - val_bag_output_loss: 0.6449 - val_footwear_output_loss: 0.9527 - val_pose_output_loss: 0.0793 - val_emotion_output_loss: 0.6084 - val_gender_output_acc: 0.9072 - val_image_quality_output_acc: 0.6832 - val_age_output_acc: 0.7444 - val_weight_output_acc: 0.8144 - val_bag_output_acc: 0.7899 - val_footwear_output_acc: 0.6470 - val_pose_output_acc: 0.9711 - val_emotion_output_acc: 0.7595\n",
      "Epoch 41/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.9690 - gender_output_loss: 0.0710 - image_quality_output_loss: 0.2997 - age_output_loss: 0.7590 - weight_output_loss: 0.5472 - bag_output_loss: 0.3692 - footwear_output_loss: 0.3906 - pose_output_loss: 0.1283 - emotion_output_loss: 0.6660 - gender_output_acc: 0.9723 - image_quality_output_acc: 0.8796 - age_output_acc: 0.6683 - weight_output_acc: 0.7871 - bag_output_acc: 0.8622 - footwear_output_acc: 0.8213 - pose_output_acc: 0.9514 - emotion_output_acc: 0.7584 - val_loss: 5.9273 - val_gender_output_loss: 0.0455 - val_image_quality_output_loss: 0.3560 - val_age_output_loss: 0.9065 - val_weight_output_loss: 0.6496 - val_bag_output_loss: 0.8224 - val_footwear_output_loss: 1.7190 - val_pose_output_loss: 0.0808 - val_emotion_output_loss: 0.6008 - val_gender_output_acc: 0.9826 - val_image_quality_output_acc: 0.8418 - val_age_output_acc: 0.5951 - val_weight_output_acc: 0.7353 - val_bag_output_acc: 0.6829 - val_footwear_output_acc: 0.5726 - val_pose_output_acc: 0.9697 - val_emotion_output_acc: 0.7803\n",
      "Epoch 42/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.9489 - gender_output_loss: 0.0659 - image_quality_output_loss: 0.3080 - age_output_loss: 0.7441 - weight_output_loss: 0.5459 - bag_output_loss: 0.3574 - footwear_output_loss: 0.4029 - pose_output_loss: 0.1263 - emotion_output_loss: 0.6450 - gender_output_acc: 0.9721 - image_quality_output_acc: 0.8768 - age_output_acc: 0.6795 - weight_output_acc: 0.7871 - bag_output_acc: 0.8640 - footwear_output_acc: 0.8161 - pose_output_acc: 0.9536 - emotion_output_acc: 0.7622 - val_loss: 4.3960 - val_gender_output_loss: 0.4109 - val_image_quality_output_loss: 0.3737 - val_age_output_loss: 0.7623 - val_weight_output_loss: 0.7984 - val_bag_output_loss: 0.2856 - val_footwear_output_loss: 0.3441 - val_pose_output_loss: 0.0734 - val_emotion_output_loss: 0.5866 - val_gender_output_acc: 0.8603 - val_image_quality_output_acc: 0.8471 - val_age_output_acc: 0.6589 - val_weight_output_acc: 0.6747 - val_bag_output_acc: 0.8933 - val_footwear_output_acc: 0.8391 - val_pose_output_acc: 0.9749 - val_emotion_output_acc: 0.7907\n",
      "Epoch 43/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.8684 - gender_output_loss: 0.0741 - image_quality_output_loss: 0.2867 - age_output_loss: 0.7209 - weight_output_loss: 0.5185 - bag_output_loss: 0.3491 - footwear_output_loss: 0.3955 - pose_output_loss: 0.1275 - emotion_output_loss: 0.6291 - gender_output_acc: 0.9694 - image_quality_output_acc: 0.8847 - age_output_acc: 0.6910 - weight_output_acc: 0.7957 - bag_output_acc: 0.8707 - footwear_output_acc: 0.8133 - pose_output_acc: 0.9514 - emotion_output_acc: 0.7711 - val_loss: 4.3751 - val_gender_output_loss: 0.2411 - val_image_quality_output_loss: 0.7152 - val_age_output_loss: 0.8339 - val_weight_output_loss: 0.5475 - val_bag_output_loss: 0.2724 - val_footwear_output_loss: 0.3852 - val_pose_output_loss: 0.0637 - val_emotion_output_loss: 0.5419 - val_gender_output_acc: 0.9174 - val_image_quality_output_acc: 0.6850 - val_age_output_acc: 0.6312 - val_weight_output_acc: 0.7807 - val_bag_output_acc: 0.8964 - val_footwear_output_acc: 0.8156 - val_pose_output_acc: 0.9780 - val_emotion_output_acc: 0.7937\n",
      "Epoch 44/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.8223 - gender_output_loss: 0.0690 - image_quality_output_loss: 0.2831 - age_output_loss: 0.7233 - weight_output_loss: 0.5035 - bag_output_loss: 0.3435 - footwear_output_loss: 0.3869 - pose_output_loss: 0.1277 - emotion_output_loss: 0.6047 - gender_output_acc: 0.9686 - image_quality_output_acc: 0.8891 - age_output_acc: 0.6919 - weight_output_acc: 0.8004 - bag_output_acc: 0.8695 - footwear_output_acc: 0.8196 - pose_output_acc: 0.9532 - emotion_output_acc: 0.7781 - val_loss: 5.2539 - val_gender_output_loss: 0.0344 - val_image_quality_output_loss: 0.2649 - val_age_output_loss: 0.6293 - val_weight_output_loss: 0.4715 - val_bag_output_loss: 0.6708 - val_footwear_output_loss: 1.6053 - val_pose_output_loss: 0.1238 - val_emotion_output_loss: 0.6654 - val_gender_output_acc: 0.9883 - val_image_quality_output_acc: 0.8873 - val_age_output_acc: 0.7552 - val_weight_output_acc: 0.8090 - val_bag_output_acc: 0.7833 - val_footwear_output_acc: 0.6014 - val_pose_output_acc: 0.9532 - val_emotion_output_acc: 0.7700\n",
      "Epoch 45/100\n",
      "359/360 [============================>.] - ETA: 0s - loss: 3.7634 - gender_output_loss: 0.0727 - image_quality_output_loss: 0.2626 - age_output_loss: 0.6953 - weight_output_loss: 0.4884 - bag_output_loss: 0.3422 - footwear_output_loss: 0.3858 - pose_output_loss: 0.1388 - emotion_output_loss: 0.5846 - gender_output_acc: 0.9691 - image_quality_output_acc: 0.8966 - age_output_acc: 0.7051 - weight_output_acc: 0.8020 - bag_output_acc: 0.8725 - footwear_output_acc: 0.8182 - pose_output_acc: 0.9486 - emotion_output_acc: 0.7839Epoch 45/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.7635 - gender_output_loss: 0.0726 - image_quality_output_loss: 0.2623 - age_output_loss: 0.6955 - weight_output_loss: 0.4880 - bag_output_loss: 0.3424 - footwear_output_loss: 0.3860 - pose_output_loss: 0.1388 - emotion_output_loss: 0.5847 - gender_output_acc: 0.9692 - image_quality_output_acc: 0.8967 - age_output_acc: 0.7049 - weight_output_acc: 0.8022 - bag_output_acc: 0.8723 - footwear_output_acc: 0.8183 - pose_output_acc: 0.9485 - emotion_output_acc: 0.7838 - val_loss: 5.0716 - val_gender_output_loss: 0.0268 - val_image_quality_output_loss: 1.4703 - val_age_output_loss: 0.6085 - val_weight_output_loss: 0.3959 - val_bag_output_loss: 0.2728 - val_footwear_output_loss: 0.6737 - val_pose_output_loss: 0.2554 - val_emotion_output_loss: 0.5686 - val_gender_output_acc: 0.9901 - val_image_quality_output_acc: 0.4155 - val_age_output_acc: 0.7481 - val_weight_output_acc: 0.8412 - val_bag_output_acc: 0.9022 - val_footwear_output_acc: 0.7238 - val_pose_output_acc: 0.9091 - val_emotion_output_acc: 0.7827\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 40s 112ms/step - loss: 3.7123 - gender_output_loss: 0.0629 - image_quality_output_loss: 0.2630 - age_output_loss: 0.6985 - weight_output_loss: 0.4765 - bag_output_loss: 0.3355 - footwear_output_loss: 0.3807 - pose_output_loss: 0.1283 - emotion_output_loss: 0.5620 - gender_output_acc: 0.9734 - image_quality_output_acc: 0.8997 - age_output_acc: 0.6984 - weight_output_acc: 0.8067 - bag_output_acc: 0.8726 - footwear_output_acc: 0.8224 - pose_output_acc: 0.9517 - emotion_output_acc: 0.7895 - val_loss: 6.0192 - val_gender_output_loss: 0.0259 - val_image_quality_output_loss: 0.3255 - val_age_output_loss: 0.8766 - val_weight_output_loss: 1.0081 - val_bag_output_loss: 0.5682 - val_footwear_output_loss: 1.6624 - val_pose_output_loss: 0.1355 - val_emotion_output_loss: 0.6064 - val_gender_output_acc: 0.9910 - val_image_quality_output_acc: 0.8614 - val_age_output_acc: 0.6033 - val_weight_output_acc: 0.5928 - val_bag_output_acc: 0.7861 - val_footwear_output_acc: 0.5590 - val_pose_output_acc: 0.9468 - val_emotion_output_acc: 0.7826\n",
      "Epoch 47/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 3.6989 - gender_output_loss: 0.0696 - image_quality_output_loss: 0.2676 - age_output_loss: 0.6809 - weight_output_loss: 0.4701 - bag_output_loss: 0.3334 - footwear_output_loss: 0.3815 - pose_output_loss: 0.1271 - emotion_output_loss: 0.5532 - gender_output_acc: 0.9707 - image_quality_output_acc: 0.8920 - age_output_acc: 0.7154 - weight_output_acc: 0.8105 - bag_output_acc: 0.8730 - footwear_output_acc: 0.8225 - pose_output_acc: 0.9516 - emotion_output_acc: 0.7948 - val_loss: 4.8866 - val_gender_output_loss: 0.0477 - val_image_quality_output_loss: 0.2373 - val_age_output_loss: 0.9568 - val_weight_output_loss: 0.3620 - val_bag_output_loss: 0.5978 - val_footwear_output_loss: 1.0925 - val_pose_output_loss: 0.1582 - val_emotion_output_loss: 0.6130 - val_gender_output_acc: 0.9826 - val_image_quality_output_acc: 0.9079 - val_age_output_acc: 0.5480 - val_weight_output_acc: 0.8547 - val_bag_output_acc: 0.8042 - val_footwear_output_acc: 0.6254 - val_pose_output_acc: 0.9377 - val_emotion_output_acc: 0.7674\n",
      "Epoch 48/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.6609 - gender_output_loss: 0.0615 - image_quality_output_loss: 0.2495 - age_output_loss: 0.6772 - weight_output_loss: 0.4537 - bag_output_loss: 0.3339 - footwear_output_loss: 0.3887 - pose_output_loss: 0.1325 - emotion_output_loss: 0.5375 - gender_output_acc: 0.9738 - image_quality_output_acc: 0.9036 - age_output_acc: 0.7144 - weight_output_acc: 0.8178 - bag_output_acc: 0.8753 - footwear_output_acc: 0.8176 - pose_output_acc: 0.9489 - emotion_output_acc: 0.7990 - val_loss: 4.5522 - val_gender_output_loss: 0.1301 - val_image_quality_output_loss: 0.4200 - val_age_output_loss: 0.5561 - val_weight_output_loss: 0.4547 - val_bag_output_loss: 0.7621 - val_footwear_output_loss: 0.6047 - val_pose_output_loss: 0.3313 - val_emotion_output_loss: 0.4604 - val_gender_output_acc: 0.9568 - val_image_quality_output_acc: 0.8425 - val_age_output_acc: 0.7641 - val_weight_output_acc: 0.8214 - val_bag_output_acc: 0.7276 - val_footwear_output_acc: 0.7576 - val_pose_output_acc: 0.8706 - val_emotion_output_acc: 0.8253\n",
      "Epoch 49/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.6869 - gender_output_loss: 0.0742 - image_quality_output_loss: 0.2546 - age_output_loss: 0.6802 - weight_output_loss: 0.4498 - bag_output_loss: 0.3418 - footwear_output_loss: 0.3818 - pose_output_loss: 0.1346 - emotion_output_loss: 0.5314 - gender_output_acc: 0.9704 - image_quality_output_acc: 0.8977 - age_output_acc: 0.7115 - weight_output_acc: 0.8200 - bag_output_acc: 0.8754 - footwear_output_acc: 0.8193 - pose_output_acc: 0.9476 - emotion_output_acc: 0.8031 - val_loss: 5.9858 - val_gender_output_loss: 0.0268 - val_image_quality_output_loss: 1.2916 - val_age_output_loss: 0.8323 - val_weight_output_loss: 0.4908 - val_bag_output_loss: 0.4568 - val_footwear_output_loss: 1.3001 - val_pose_output_loss: 0.2784 - val_emotion_output_loss: 0.4630 - val_gender_output_acc: 0.9911 - val_image_quality_output_acc: 0.5171 - val_age_output_acc: 0.6277 - val_weight_output_acc: 0.8182 - val_bag_output_acc: 0.8272 - val_footwear_output_acc: 0.6161 - val_pose_output_acc: 0.8931 - val_emotion_output_acc: 0.8213\n",
      "Epoch 50/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.6093 - gender_output_loss: 0.0602 - image_quality_output_loss: 0.2473 - age_output_loss: 0.6675 - weight_output_loss: 0.4397 - bag_output_loss: 0.3346 - footwear_output_loss: 0.3774 - pose_output_loss: 0.1263 - emotion_output_loss: 0.5059 - gender_output_acc: 0.9763 - image_quality_output_acc: 0.9010 - age_output_acc: 0.7148 - weight_output_acc: 0.8266 - bag_output_acc: 0.8747 - footwear_output_acc: 0.8199 - pose_output_acc: 0.9519 - emotion_output_acc: 0.8075 - val_loss: 3.8471 - val_gender_output_loss: 0.0284 - val_image_quality_output_loss: 0.1714 - val_age_output_loss: 0.6799 - val_weight_output_loss: 0.9147 - val_bag_output_loss: 0.2771 - val_footwear_output_loss: 0.3291 - val_pose_output_loss: 0.1486 - val_emotion_output_loss: 0.4429 - val_gender_output_acc: 0.9906 - val_image_quality_output_acc: 0.9334 - val_age_output_acc: 0.6845 - val_weight_output_acc: 0.6122 - val_bag_output_acc: 0.8933 - val_footwear_output_acc: 0.8401 - val_pose_output_acc: 0.9462 - val_emotion_output_acc: 0.8373\n",
      "Epoch 51/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.5975 - gender_output_loss: 0.0627 - image_quality_output_loss: 0.2387 - age_output_loss: 0.6572 - weight_output_loss: 0.4417 - bag_output_loss: 0.3265 - footwear_output_loss: 0.3788 - pose_output_loss: 0.1311 - emotion_output_loss: 0.5005 - gender_output_acc: 0.9728 - image_quality_output_acc: 0.9086 - age_output_acc: 0.7209 - weight_output_acc: 0.8233 - bag_output_acc: 0.8772 - footwear_output_acc: 0.8196 - pose_output_acc: 0.9497 - emotion_output_acc: 0.8099 - val_loss: 3.9822 - val_gender_output_loss: 0.0199 - val_image_quality_output_loss: 0.6418 - val_age_output_loss: 0.8073 - val_weight_output_loss: 0.3342 - val_bag_output_loss: 0.2649 - val_footwear_output_loss: 0.4344 - val_pose_output_loss: 0.0798 - val_emotion_output_loss: 0.5340 - val_gender_output_acc: 0.9927 - val_image_quality_output_acc: 0.7618 - val_age_output_acc: 0.6245 - val_weight_output_acc: 0.8561 - val_bag_output_acc: 0.8977 - val_footwear_output_acc: 0.8095 - val_pose_output_acc: 0.9728 - val_emotion_output_acc: 0.7976\n",
      "Epoch 52/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.5696 - gender_output_loss: 0.0721 - image_quality_output_loss: 0.2342 - age_output_loss: 0.6433 - weight_output_loss: 0.4258 - bag_output_loss: 0.3260 - footwear_output_loss: 0.3832 - pose_output_loss: 0.1317 - emotion_output_loss: 0.4822 - gender_output_acc: 0.9685 - image_quality_output_acc: 0.9078 - age_output_acc: 0.7280 - weight_output_acc: 0.8316 - bag_output_acc: 0.8747 - footwear_output_acc: 0.8201 - pose_output_acc: 0.9515 - emotion_output_acc: 0.8134 - val_loss: 4.6214 - val_gender_output_loss: 0.0387 - val_image_quality_output_loss: 0.2365 - val_age_output_loss: 0.5140 - val_weight_output_loss: 0.4299 - val_bag_output_loss: 0.2960 - val_footwear_output_loss: 1.7456 - val_pose_output_loss: 0.0505 - val_emotion_output_loss: 0.4325 - val_gender_output_acc: 0.9865 - val_image_quality_output_acc: 0.9016 - val_age_output_acc: 0.7915 - val_weight_output_acc: 0.8247 - val_bag_output_acc: 0.8898 - val_footwear_output_acc: 0.5737 - val_pose_output_acc: 0.9840 - val_emotion_output_acc: 0.8339\n",
      "Epoch 53/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.5695 - gender_output_loss: 0.0672 - image_quality_output_loss: 0.2299 - age_output_loss: 0.6414 - weight_output_loss: 0.4105 - bag_output_loss: 0.3376 - footwear_output_loss: 0.3798 - pose_output_loss: 0.1359 - emotion_output_loss: 0.4848 - gender_output_acc: 0.9707 - image_quality_output_acc: 0.9090 - age_output_acc: 0.7286 - weight_output_acc: 0.8368 - bag_output_acc: 0.8718 - footwear_output_acc: 0.8208 - pose_output_acc: 0.9485 - emotion_output_acc: 0.8176 - val_loss: 6.1071 - val_gender_output_loss: 0.2556 - val_image_quality_output_loss: 0.2905 - val_age_output_loss: 1.8769 - val_weight_output_loss: 0.3187 - val_bag_output_loss: 1.0543 - val_footwear_output_loss: 0.9176 - val_pose_output_loss: 0.0941 - val_emotion_output_loss: 0.4118 - val_gender_output_acc: 0.9036 - val_image_quality_output_acc: 0.8812 - val_age_output_acc: 0.2220 - val_weight_output_acc: 0.8964 - val_bag_output_acc: 0.6261 - val_footwear_output_acc: 0.6663 - val_pose_output_acc: 0.9655 - val_emotion_output_acc: 0.8306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.5328 - gender_output_loss: 0.0581 - image_quality_output_loss: 0.2203 - age_output_loss: 0.6496 - weight_output_loss: 0.4071 - bag_output_loss: 0.3240 - footwear_output_loss: 0.3700 - pose_output_loss: 0.1397 - emotion_output_loss: 0.4725 - gender_output_acc: 0.9750 - image_quality_output_acc: 0.9135 - age_output_acc: 0.7240 - weight_output_acc: 0.8376 - bag_output_acc: 0.8789 - footwear_output_acc: 0.8235 - pose_output_acc: 0.9476 - emotion_output_acc: 0.8155 - val_loss: 5.6184 - val_gender_output_loss: 0.0141 - val_image_quality_output_loss: 1.3544 - val_age_output_loss: 0.7067 - val_weight_output_loss: 0.3048 - val_bag_output_loss: 1.4184 - val_footwear_output_loss: 0.4325 - val_pose_output_loss: 0.0990 - val_emotion_output_loss: 0.3913 - val_gender_output_acc: 0.9953 - val_image_quality_output_acc: 0.5005 - val_age_output_acc: 0.6915 - val_weight_output_acc: 0.8767 - val_bag_output_acc: 0.5510 - val_footwear_output_acc: 0.8060 - val_pose_output_acc: 0.9646 - val_emotion_output_acc: 0.8367\n",
      "Epoch 55/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.5290 - gender_output_loss: 0.0659 - image_quality_output_loss: 0.2289 - age_output_loss: 0.6543 - weight_output_loss: 0.3945 - bag_output_loss: 0.3194 - footwear_output_loss: 0.3698 - pose_output_loss: 0.1284 - emotion_output_loss: 0.4662 - gender_output_acc: 0.9707 - image_quality_output_acc: 0.9131 - age_output_acc: 0.7243 - weight_output_acc: 0.8438 - bag_output_acc: 0.8803 - footwear_output_acc: 0.8273 - pose_output_acc: 0.9516 - emotion_output_acc: 0.8165 - val_loss: 5.7179 - val_gender_output_loss: 0.0678 - val_image_quality_output_loss: 0.2530 - val_age_output_loss: 0.8987 - val_weight_output_loss: 1.0762 - val_bag_output_loss: 1.2999 - val_footwear_output_loss: 0.3543 - val_pose_output_loss: 0.1223 - val_emotion_output_loss: 0.7394 - val_gender_output_acc: 0.9749 - val_image_quality_output_acc: 0.8916 - val_age_output_acc: 0.6016 - val_weight_output_acc: 0.5986 - val_bag_output_acc: 0.5611 - val_footwear_output_acc: 0.8238 - val_pose_output_acc: 0.9507 - val_emotion_output_acc: 0.7037\n",
      "Epoch 56/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.4893 - gender_output_loss: 0.0669 - image_quality_output_loss: 0.2103 - age_output_loss: 0.6343 - weight_output_loss: 0.3854 - bag_output_loss: 0.3174 - footwear_output_loss: 0.3667 - pose_output_loss: 0.1339 - emotion_output_loss: 0.4654 - gender_output_acc: 0.9707 - image_quality_output_acc: 0.9214 - age_output_acc: 0.7331 - weight_output_acc: 0.8487 - bag_output_acc: 0.8809 - footwear_output_acc: 0.8254 - pose_output_acc: 0.9501 - emotion_output_acc: 0.8167 - val_loss: 5.3313 - val_gender_output_loss: 0.0654 - val_image_quality_output_loss: 1.2028 - val_age_output_loss: 0.7336 - val_weight_output_loss: 0.5410 - val_bag_output_loss: 0.2293 - val_footwear_output_loss: 1.0394 - val_pose_output_loss: 0.0973 - val_emotion_output_loss: 0.5085 - val_gender_output_acc: 0.9747 - val_image_quality_output_acc: 0.5515 - val_age_output_acc: 0.6833 - val_weight_output_acc: 0.7812 - val_bag_output_acc: 0.9133 - val_footwear_output_acc: 0.6358 - val_pose_output_acc: 0.9635 - val_emotion_output_acc: 0.8057\n",
      "Epoch 57/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.4865 - gender_output_loss: 0.0576 - image_quality_output_loss: 0.2223 - age_output_loss: 0.6311 - weight_output_loss: 0.3861 - bag_output_loss: 0.3190 - footwear_output_loss: 0.3645 - pose_output_loss: 0.1285 - emotion_output_loss: 0.4593 - gender_output_acc: 0.9737 - image_quality_output_acc: 0.9128 - age_output_acc: 0.7306 - weight_output_acc: 0.8475 - bag_output_acc: 0.8819 - footwear_output_acc: 0.8285 - pose_output_acc: 0.9506 - emotion_output_acc: 0.8173 - val_loss: 6.6149 - val_gender_output_loss: 0.0583 - val_image_quality_output_loss: 0.1629 - val_age_output_loss: 0.8695 - val_weight_output_loss: 0.4860 - val_bag_output_loss: 1.2544 - val_footwear_output_loss: 1.7523 - val_pose_output_loss: 0.1030 - val_emotion_output_loss: 1.0049 - val_gender_output_acc: 0.9780 - val_image_quality_output_acc: 0.9384 - val_age_output_acc: 0.6043 - val_weight_output_acc: 0.7958 - val_bag_output_acc: 0.6787 - val_footwear_output_acc: 0.6041 - val_pose_output_acc: 0.9609 - val_emotion_output_acc: 0.7472\n",
      "Epoch 58/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.5266 - gender_output_loss: 0.0715 - image_quality_output_loss: 0.2270 - age_output_loss: 0.6307 - weight_output_loss: 0.3770 - bag_output_loss: 0.3237 - footwear_output_loss: 0.3702 - pose_output_loss: 0.1337 - emotion_output_loss: 0.4641 - gender_output_acc: 0.9701 - image_quality_output_acc: 0.9132 - age_output_acc: 0.7376 - weight_output_acc: 0.8544 - bag_output_acc: 0.8806 - footwear_output_acc: 0.8286 - pose_output_acc: 0.9512 - emotion_output_acc: 0.8159 - val_loss: 6.9796 - val_gender_output_loss: 0.1785 - val_image_quality_output_loss: 0.3041 - val_age_output_loss: 0.7985 - val_weight_output_loss: 0.5014 - val_bag_output_loss: 0.6787 - val_footwear_output_loss: 1.4429 - val_pose_output_loss: 1.5165 - val_emotion_output_loss: 0.6242 - val_gender_output_acc: 0.9497 - val_image_quality_output_acc: 0.8701 - val_age_output_acc: 0.6529 - val_weight_output_acc: 0.7814 - val_bag_output_acc: 0.7868 - val_footwear_output_acc: 0.6281 - val_pose_output_acc: 0.7043 - val_emotion_output_acc: 0.7613\n",
      "Epoch 59/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.4922 - gender_output_loss: 0.0650 - image_quality_output_loss: 0.2202 - age_output_loss: 0.6171 - weight_output_loss: 0.3742 - bag_output_loss: 0.3166 - footwear_output_loss: 0.3731 - pose_output_loss: 0.1342 - emotion_output_loss: 0.4534 - gender_output_acc: 0.9715 - image_quality_output_acc: 0.9152 - age_output_acc: 0.7397 - weight_output_acc: 0.8523 - bag_output_acc: 0.8797 - footwear_output_acc: 0.8261 - pose_output_acc: 0.9507 - emotion_output_acc: 0.8208 - val_loss: 6.1445 - val_gender_output_loss: 0.0603 - val_image_quality_output_loss: 0.3362 - val_age_output_loss: 1.1741 - val_weight_output_loss: 0.2401 - val_bag_output_loss: 0.6983 - val_footwear_output_loss: 0.3652 - val_pose_output_loss: 0.5568 - val_emotion_output_loss: 1.7720 - val_gender_output_acc: 0.9760 - val_image_quality_output_acc: 0.8588 - val_age_output_acc: 0.4616 - val_weight_output_acc: 0.9146 - val_bag_output_acc: 0.7970 - val_footwear_output_acc: 0.8139 - val_pose_output_acc: 0.8379 - val_emotion_output_acc: 0.4019\n",
      "Epoch 60/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.4496 - gender_output_loss: 0.0646 - image_quality_output_loss: 0.2092 - age_output_loss: 0.6254 - weight_output_loss: 0.3714 - bag_output_loss: 0.3080 - footwear_output_loss: 0.3599 - pose_output_loss: 0.1249 - emotion_output_loss: 0.4408 - gender_output_acc: 0.9722 - image_quality_output_acc: 0.9196 - age_output_acc: 0.7346 - weight_output_acc: 0.8562 - bag_output_acc: 0.8887 - footwear_output_acc: 0.8297 - pose_output_acc: 0.9533 - emotion_output_acc: 0.8242 - val_loss: 6.4925 - val_gender_output_loss: 0.6947 - val_image_quality_output_loss: 0.7068 - val_age_output_loss: 0.7114 - val_weight_output_loss: 0.2797 - val_bag_output_loss: 0.2489 - val_footwear_output_loss: 0.6555 - val_pose_output_loss: 0.3309 - val_emotion_output_loss: 1.9147 - val_gender_output_acc: 0.7939 - val_image_quality_output_acc: 0.7223 - val_age_output_acc: 0.7014 - val_weight_output_acc: 0.9186 - val_bag_output_acc: 0.9039 - val_footwear_output_acc: 0.7424 - val_pose_output_acc: 0.8589 - val_emotion_output_acc: 0.3644\n",
      "Epoch 61/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.4779 - gender_output_loss: 0.0635 - image_quality_output_loss: 0.2061 - age_output_loss: 0.6223 - weight_output_loss: 0.3680 - bag_output_loss: 0.3078 - footwear_output_loss: 0.3693 - pose_output_loss: 0.1360 - emotion_output_loss: 0.4508 - gender_output_acc: 0.9739 - image_quality_output_acc: 0.9214 - age_output_acc: 0.7392 - weight_output_acc: 0.8543 - bag_output_acc: 0.8844 - footwear_output_acc: 0.8286 - pose_output_acc: 0.9483 - emotion_output_acc: 0.8231 - val_loss: 3.3029 - val_gender_output_loss: 0.1993 - val_image_quality_output_loss: 0.3912 - val_age_output_loss: 0.4498 - val_weight_output_loss: 0.2510 - val_bag_output_loss: 0.2542 - val_footwear_output_loss: 0.2950 - val_pose_output_loss: 0.0394 - val_emotion_output_loss: 0.4635 - val_gender_output_acc: 0.9259 - val_image_quality_output_acc: 0.8439 - val_age_output_acc: 0.8329 - val_weight_output_acc: 0.8949 - val_bag_output_acc: 0.9081 - val_footwear_output_acc: 0.8666 - val_pose_output_acc: 0.9889 - val_emotion_output_acc: 0.8207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.4105 - gender_output_loss: 0.0616 - image_quality_output_loss: 0.1956 - age_output_loss: 0.6023 - weight_output_loss: 0.3593 - bag_output_loss: 0.3090 - footwear_output_loss: 0.3516 - pose_output_loss: 0.1300 - emotion_output_loss: 0.4385 - gender_output_acc: 0.9725 - image_quality_output_acc: 0.9257 - age_output_acc: 0.7514 - weight_output_acc: 0.8592 - bag_output_acc: 0.8821 - footwear_output_acc: 0.8385 - pose_output_acc: 0.9506 - emotion_output_acc: 0.8277 - val_loss: 5.3482 - val_gender_output_loss: 0.7329 - val_image_quality_output_loss: 0.3304 - val_age_output_loss: 1.4317 - val_weight_output_loss: 0.3120 - val_bag_output_loss: 0.5746 - val_footwear_output_loss: 0.4591 - val_pose_output_loss: 0.1454 - val_emotion_output_loss: 0.3963 - val_gender_output_acc: 0.7954 - val_image_quality_output_acc: 0.8719 - val_age_output_acc: 0.3949 - val_weight_output_acc: 0.8685 - val_bag_output_acc: 0.7716 - val_footwear_output_acc: 0.7840 - val_pose_output_acc: 0.9437 - val_emotion_output_acc: 0.8303\n",
      "Epoch 63/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.4280 - gender_output_loss: 0.0629 - image_quality_output_loss: 0.2062 - age_output_loss: 0.6065 - weight_output_loss: 0.3569 - bag_output_loss: 0.3036 - footwear_output_loss: 0.3498 - pose_output_loss: 0.1263 - emotion_output_loss: 0.4460 - gender_output_acc: 0.9737 - image_quality_output_acc: 0.9220 - age_output_acc: 0.7470 - weight_output_acc: 0.8587 - bag_output_acc: 0.8870 - footwear_output_acc: 0.8411 - pose_output_acc: 0.9521 - emotion_output_acc: 0.8234 - val_loss: 8.7367 - val_gender_output_loss: 0.0344 - val_image_quality_output_loss: 2.0331 - val_age_output_loss: 0.4384 - val_weight_output_loss: 0.2663 - val_bag_output_loss: 2.1335 - val_footwear_output_loss: 0.3072 - val_pose_output_loss: 0.0966 - val_emotion_output_loss: 2.4530 - val_gender_output_acc: 0.9878 - val_image_quality_output_acc: 0.4572 - val_age_output_acc: 0.8375 - val_weight_output_acc: 0.8872 - val_bag_output_acc: 0.4235 - val_footwear_output_acc: 0.8686 - val_pose_output_acc: 0.9635 - val_emotion_output_acc: 0.2875\n",
      "Epoch 64/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.4136 - gender_output_loss: 0.0635 - image_quality_output_loss: 0.2052 - age_output_loss: 0.6022 - weight_output_loss: 0.3506 - bag_output_loss: 0.2974 - footwear_output_loss: 0.3577 - pose_output_loss: 0.1219 - emotion_output_loss: 0.4381 - gender_output_acc: 0.9723 - image_quality_output_acc: 0.9245 - age_output_acc: 0.7473 - weight_output_acc: 0.8657 - bag_output_acc: 0.8893 - footwear_output_acc: 0.8354 - pose_output_acc: 0.9540 - emotion_output_acc: 0.8248 - val_loss: 4.3371 - val_gender_output_loss: 0.1251 - val_image_quality_output_loss: 0.4779 - val_age_output_loss: 0.4302 - val_weight_output_loss: 0.4555 - val_bag_output_loss: 0.2127 - val_footwear_output_loss: 0.7102 - val_pose_output_loss: 0.0750 - val_emotion_output_loss: 0.8695 - val_gender_output_acc: 0.9536 - val_image_quality_output_acc: 0.8045 - val_age_output_acc: 0.8461 - val_weight_output_acc: 0.8025 - val_bag_output_acc: 0.9223 - val_footwear_output_acc: 0.7335 - val_pose_output_acc: 0.9694 - val_emotion_output_acc: 0.7655\n",
      "Epoch 65/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.3954 - gender_output_loss: 0.0571 - image_quality_output_loss: 0.1878 - age_output_loss: 0.6047 - weight_output_loss: 0.3617 - bag_output_loss: 0.2987 - footwear_output_loss: 0.3403 - pose_output_loss: 0.1198 - emotion_output_loss: 0.4407 - gender_output_acc: 0.9726 - image_quality_output_acc: 0.9315 - age_output_acc: 0.7447 - weight_output_acc: 0.8564 - bag_output_acc: 0.8886 - footwear_output_acc: 0.8447 - pose_output_acc: 0.9523 - emotion_output_acc: 0.8224 - val_loss: 4.9782 - val_gender_output_loss: 0.0726 - val_image_quality_output_loss: 0.3572 - val_age_output_loss: 0.5902 - val_weight_output_loss: 0.2516 - val_bag_output_loss: 0.2149 - val_footwear_output_loss: 0.6668 - val_pose_output_loss: 0.0428 - val_emotion_output_loss: 1.7935 - val_gender_output_acc: 0.9740 - val_image_quality_output_acc: 0.8656 - val_age_output_acc: 0.7405 - val_weight_output_acc: 0.8865 - val_bag_output_acc: 0.9138 - val_footwear_output_acc: 0.7604 - val_pose_output_acc: 0.9863 - val_emotion_output_acc: 0.7217\n",
      "Epoch 66/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 3.3594 - gender_output_loss: 0.0658 - image_quality_output_loss: 0.1778 - age_output_loss: 0.5944 - weight_output_loss: 0.3461 - bag_output_loss: 0.2887 - footwear_output_loss: 0.3330 - pose_output_loss: 0.1271 - emotion_output_loss: 0.4355 - gender_output_acc: 0.9729 - image_quality_output_acc: 0.9310 - age_output_acc: 0.7484 - weight_output_acc: 0.8635 - bag_output_acc: 0.8908 - footwear_output_acc: 0.8465 - pose_output_acc: 0.9510 - emotion_output_acc: 0.8292 - val_loss: 6.9221 - val_gender_output_loss: 0.0385 - val_image_quality_output_loss: 0.2419 - val_age_output_loss: 2.4048 - val_weight_output_loss: 0.7487 - val_bag_output_loss: 0.3070 - val_footwear_output_loss: 0.3055 - val_pose_output_loss: 1.1661 - val_emotion_output_loss: 0.7157 - val_gender_output_acc: 0.9845 - val_image_quality_output_acc: 0.9017 - val_age_output_acc: 0.1437 - val_weight_output_acc: 0.6443 - val_bag_output_acc: 0.8786 - val_footwear_output_acc: 0.8506 - val_pose_output_acc: 0.6656 - val_emotion_output_acc: 0.7773\n",
      "Epoch 67/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.3794 - gender_output_loss: 0.0666 - image_quality_output_loss: 0.1893 - age_output_loss: 0.5939 - weight_output_loss: 0.3551 - bag_output_loss: 0.2861 - footwear_output_loss: 0.3409 - pose_output_loss: 0.1204 - emotion_output_loss: 0.4293 - gender_output_acc: 0.9718 - image_quality_output_acc: 0.9267 - age_output_acc: 0.7508 - weight_output_acc: 0.8618 - bag_output_acc: 0.8939 - footwear_output_acc: 0.8453 - pose_output_acc: 0.9555 - emotion_output_acc: 0.8255 - val_loss: 7.0351 - val_gender_output_loss: 0.0307 - val_image_quality_output_loss: 0.8787 - val_age_output_loss: 0.8569 - val_weight_output_loss: 1.7264 - val_bag_output_loss: 0.2176 - val_footwear_output_loss: 0.4621 - val_pose_output_loss: 0.0910 - val_emotion_output_loss: 1.7691 - val_gender_output_acc: 0.9891 - val_image_quality_output_acc: 0.6990 - val_age_output_acc: 0.5974 - val_weight_output_acc: 0.3442 - val_bag_output_acc: 0.9266 - val_footwear_output_acc: 0.8042 - val_pose_output_acc: 0.9677 - val_emotion_output_acc: 0.4224\n",
      "Epoch 68/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.3950 - gender_output_loss: 0.0633 - image_quality_output_loss: 0.2009 - age_output_loss: 0.5967 - weight_output_loss: 0.3419 - bag_output_loss: 0.2829 - footwear_output_loss: 0.3382 - pose_output_loss: 0.1289 - emotion_output_loss: 0.4362 - gender_output_acc: 0.9714 - image_quality_output_acc: 0.9255 - age_output_acc: 0.7529 - weight_output_acc: 0.8674 - bag_output_acc: 0.8967 - footwear_output_acc: 0.8505 - pose_output_acc: 0.9529 - emotion_output_acc: 0.8250 - val_loss: 7.9807 - val_gender_output_loss: 0.3182 - val_image_quality_output_loss: 0.2918 - val_age_output_loss: 0.8222 - val_weight_output_loss: 0.2388 - val_bag_output_loss: 1.0510 - val_footwear_output_loss: 3.7536 - val_pose_output_loss: 0.1436 - val_emotion_output_loss: 0.3514 - val_gender_output_acc: 0.8998 - val_image_quality_output_acc: 0.8840 - val_age_output_acc: 0.5985 - val_weight_output_acc: 0.9084 - val_bag_output_acc: 0.7324 - val_footwear_output_acc: 0.4432 - val_pose_output_acc: 0.9490 - val_emotion_output_acc: 0.8469\n",
      "Epoch 69/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.3771 - gender_output_loss: 0.0613 - image_quality_output_loss: 0.1920 - age_output_loss: 0.5907 - weight_output_loss: 0.3375 - bag_output_loss: 0.2839 - footwear_output_loss: 0.3291 - pose_output_loss: 0.1336 - emotion_output_loss: 0.4342 - gender_output_acc: 0.9734 - image_quality_output_acc: 0.9257 - age_output_acc: 0.7525 - weight_output_acc: 0.8674 - bag_output_acc: 0.8923 - footwear_output_acc: 0.8516 - pose_output_acc: 0.9498 - emotion_output_acc: 0.8257 - val_loss: 7.0343 - val_gender_output_loss: 0.0916 - val_image_quality_output_loss: 0.2478 - val_age_output_loss: 0.5921 - val_weight_output_loss: 0.8532 - val_bag_output_loss: 1.7940 - val_footwear_output_loss: 0.2867 - val_pose_output_loss: 0.2598 - val_emotion_output_loss: 1.8899 - val_gender_output_acc: 0.9677 - val_image_quality_output_acc: 0.9078 - val_age_output_acc: 0.7595 - val_weight_output_acc: 0.5935 - val_bag_output_acc: 0.6180 - val_footwear_output_acc: 0.8771 - val_pose_output_acc: 0.9187 - val_emotion_output_acc: 0.4132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.3761 - gender_output_loss: 0.0651 - image_quality_output_loss: 0.2010 - age_output_loss: 0.5731 - weight_output_loss: 0.3400 - bag_output_loss: 0.2863 - footwear_output_loss: 0.3288 - pose_output_loss: 0.1267 - emotion_output_loss: 0.4330 - gender_output_acc: 0.9699 - image_quality_output_acc: 0.9240 - age_output_acc: 0.7668 - weight_output_acc: 0.8648 - bag_output_acc: 0.8936 - footwear_output_acc: 0.8532 - pose_output_acc: 0.9514 - emotion_output_acc: 0.8273 - val_loss: 7.0431 - val_gender_output_loss: 0.5163 - val_image_quality_output_loss: 0.2775 - val_age_output_loss: 0.4135 - val_weight_output_loss: 0.2084 - val_bag_output_loss: 1.3407 - val_footwear_output_loss: 0.5595 - val_pose_output_loss: 1.0504 - val_emotion_output_loss: 1.6514 - val_gender_output_acc: 0.8517 - val_image_quality_output_acc: 0.8935 - val_age_output_acc: 0.8350 - val_weight_output_acc: 0.9225 - val_bag_output_acc: 0.6918 - val_footwear_output_acc: 0.7956 - val_pose_output_acc: 0.7207 - val_emotion_output_acc: 0.7288\n",
      "Epoch 71/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.3621 - gender_output_loss: 0.0641 - image_quality_output_loss: 0.1940 - age_output_loss: 0.5914 - weight_output_loss: 0.3333 - bag_output_loss: 0.2793 - footwear_output_loss: 0.3189 - pose_output_loss: 0.1262 - emotion_output_loss: 0.4272 - gender_output_acc: 0.9713 - image_quality_output_acc: 0.9261 - age_output_acc: 0.7552 - weight_output_acc: 0.8734 - bag_output_acc: 0.8953 - footwear_output_acc: 0.8587 - pose_output_acc: 0.9503 - emotion_output_acc: 0.8332 - val_loss: 4.2590 - val_gender_output_loss: 0.2487 - val_image_quality_output_loss: 0.4339 - val_age_output_loss: 0.9804 - val_weight_output_loss: 0.2268 - val_bag_output_loss: 0.2831 - val_footwear_output_loss: 0.2579 - val_pose_output_loss: 0.3343 - val_emotion_output_loss: 0.4630 - val_gender_output_acc: 0.9150 - val_image_quality_output_acc: 0.8153 - val_age_output_acc: 0.5348 - val_weight_output_acc: 0.9125 - val_bag_output_acc: 0.8763 - val_footwear_output_acc: 0.8922 - val_pose_output_acc: 0.8774 - val_emotion_output_acc: 0.8196\n",
      "Epoch 72/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.3037 - gender_output_loss: 0.0589 - image_quality_output_loss: 0.1826 - age_output_loss: 0.5784 - weight_output_loss: 0.3321 - bag_output_loss: 0.2668 - footwear_output_loss: 0.3094 - pose_output_loss: 0.1136 - emotion_output_loss: 0.4292 - gender_output_acc: 0.9727 - image_quality_output_acc: 0.9317 - age_output_acc: 0.7610 - weight_output_acc: 0.8716 - bag_output_acc: 0.9016 - footwear_output_acc: 0.8628 - pose_output_acc: 0.9556 - emotion_output_acc: 0.8259 - val_loss: 6.5845 - val_gender_output_loss: 0.7934 - val_image_quality_output_loss: 0.3192 - val_age_output_loss: 0.4182 - val_weight_output_loss: 0.3257 - val_bag_output_loss: 1.9029 - val_footwear_output_loss: 0.8446 - val_pose_output_loss: 0.3174 - val_emotion_output_loss: 0.6277 - val_gender_output_acc: 0.7817 - val_image_quality_output_acc: 0.8881 - val_age_output_acc: 0.8286 - val_weight_output_acc: 0.8740 - val_bag_output_acc: 0.4826 - val_footwear_output_acc: 0.7401 - val_pose_output_acc: 0.8751 - val_emotion_output_acc: 0.7936\n",
      "Epoch 73/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.3272 - gender_output_loss: 0.0657 - image_quality_output_loss: 0.1867 - age_output_loss: 0.5775 - weight_output_loss: 0.3316 - bag_output_loss: 0.2712 - footwear_output_loss: 0.3130 - pose_output_loss: 0.1215 - emotion_output_loss: 0.4211 - gender_output_acc: 0.9719 - image_quality_output_acc: 0.9306 - age_output_acc: 0.7589 - weight_output_acc: 0.8698 - bag_output_acc: 0.9003 - footwear_output_acc: 0.8628 - pose_output_acc: 0.9538 - emotion_output_acc: 0.8279 - val_loss: 7.7756 - val_gender_output_loss: 1.2012 - val_image_quality_output_loss: 1.8653 - val_age_output_loss: 0.8499 - val_weight_output_loss: 0.2207 - val_bag_output_loss: 0.3204 - val_footwear_output_loss: 1.8369 - val_pose_output_loss: 0.0493 - val_emotion_output_loss: 0.3885 - val_gender_output_acc: 0.7298 - val_image_quality_output_acc: 0.6937 - val_age_output_acc: 0.6160 - val_weight_output_acc: 0.9063 - val_bag_output_acc: 0.8827 - val_footwear_output_acc: 0.5614 - val_pose_output_acc: 0.9827 - val_emotion_output_acc: 0.8352\n",
      "Epoch 74/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.3160 - gender_output_loss: 0.0621 - image_quality_output_loss: 0.1754 - age_output_loss: 0.5776 - weight_output_loss: 0.3359 - bag_output_loss: 0.2671 - footwear_output_loss: 0.3065 - pose_output_loss: 0.1217 - emotion_output_loss: 0.4242 - gender_output_acc: 0.9739 - image_quality_output_acc: 0.9364 - age_output_acc: 0.7582 - weight_output_acc: 0.8711 - bag_output_acc: 0.9019 - footwear_output_acc: 0.8655 - pose_output_acc: 0.9536 - emotion_output_acc: 0.8293 - val_loss: 9.6089 - val_gender_output_loss: 0.0235 - val_image_quality_output_loss: 3.2968 - val_age_output_loss: 1.3159 - val_weight_output_loss: 0.5860 - val_bag_output_loss: 0.8371 - val_footwear_output_loss: 0.2756 - val_pose_output_loss: 1.2460 - val_emotion_output_loss: 0.9792 - val_gender_output_acc: 0.9916 - val_image_quality_output_acc: 0.3484 - val_age_output_acc: 0.4536 - val_weight_output_acc: 0.7843 - val_bag_output_acc: 0.7835 - val_footwear_output_acc: 0.8945 - val_pose_output_acc: 0.8096 - val_emotion_output_acc: 0.6458\n",
      "Epoch 75/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.3230 - gender_output_loss: 0.0660 - image_quality_output_loss: 0.1885 - age_output_loss: 0.5768 - weight_output_loss: 0.3344 - bag_output_loss: 0.2655 - footwear_output_loss: 0.2984 - pose_output_loss: 0.1218 - emotion_output_loss: 0.4199 - gender_output_acc: 0.9714 - image_quality_output_acc: 0.9294 - age_output_acc: 0.7651 - weight_output_acc: 0.8716 - bag_output_acc: 0.8977 - footwear_output_acc: 0.8676 - pose_output_acc: 0.9541 - emotion_output_acc: 0.8274 - val_loss: 7.3056 - val_gender_output_loss: 0.1234 - val_image_quality_output_loss: 3.9907 - val_age_output_loss: 0.5406 - val_weight_output_loss: 0.2970 - val_bag_output_loss: 0.4497 - val_footwear_output_loss: 0.2461 - val_pose_output_loss: 0.1622 - val_emotion_output_loss: 0.4412 - val_gender_output_acc: 0.9535 - val_image_quality_output_acc: 0.3109 - val_age_output_acc: 0.7564 - val_weight_output_acc: 0.8837 - val_bag_output_acc: 0.8628 - val_footwear_output_acc: 0.9061 - val_pose_output_acc: 0.9288 - val_emotion_output_acc: 0.8284\n",
      "Epoch 76/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.2968 - gender_output_loss: 0.0637 - image_quality_output_loss: 0.1836 - age_output_loss: 0.5720 - weight_output_loss: 0.3303 - bag_output_loss: 0.2576 - footwear_output_loss: 0.2902 - pose_output_loss: 0.1229 - emotion_output_loss: 0.4199 - gender_output_acc: 0.9730 - image_quality_output_acc: 0.9329 - age_output_acc: 0.7648 - weight_output_acc: 0.8707 - bag_output_acc: 0.9032 - footwear_output_acc: 0.8711 - pose_output_acc: 0.9549 - emotion_output_acc: 0.8319 - val_loss: 8.2354 - val_gender_output_loss: 0.0634 - val_image_quality_output_loss: 1.2789 - val_age_output_loss: 0.8578 - val_weight_output_loss: 0.9830 - val_bag_output_loss: 0.6984 - val_footwear_output_loss: 0.3026 - val_pose_output_loss: 0.1989 - val_emotion_output_loss: 2.7929 - val_gender_output_acc: 0.9762 - val_image_quality_output_acc: 0.5997 - val_age_output_acc: 0.6082 - val_weight_output_acc: 0.5754 - val_bag_output_acc: 0.7944 - val_footwear_output_acc: 0.8796 - val_pose_output_acc: 0.9154 - val_emotion_output_acc: 0.2858\n",
      "Epoch 77/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.3401 - gender_output_loss: 0.0696 - image_quality_output_loss: 0.1889 - age_output_loss: 0.5882 - weight_output_loss: 0.3327 - bag_output_loss: 0.2631 - footwear_output_loss: 0.2921 - pose_output_loss: 0.1098 - emotion_output_loss: 0.4328 - gender_output_acc: 0.9722 - image_quality_output_acc: 0.9302 - age_output_acc: 0.7556 - weight_output_acc: 0.8660 - bag_output_acc: 0.9023 - footwear_output_acc: 0.8725 - pose_output_acc: 0.9585 - emotion_output_acc: 0.8260 - val_loss: 3.9468 - val_gender_output_loss: 0.0265 - val_image_quality_output_loss: 0.2585 - val_age_output_loss: 0.5187 - val_weight_output_loss: 0.6991 - val_bag_output_loss: 0.7343 - val_footwear_output_loss: 0.2287 - val_pose_output_loss: 0.0314 - val_emotion_output_loss: 0.3818 - val_gender_output_acc: 0.9898 - val_image_quality_output_acc: 0.9020 - val_age_output_acc: 0.7945 - val_weight_output_acc: 0.7307 - val_bag_output_acc: 0.7358 - val_footwear_output_acc: 0.9056 - val_pose_output_acc: 0.9900 - val_emotion_output_acc: 0.8420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.3165 - gender_output_loss: 0.0582 - image_quality_output_loss: 0.1764 - age_output_loss: 0.5740 - weight_output_loss: 0.3358 - bag_output_loss: 0.2634 - footwear_output_loss: 0.2981 - pose_output_loss: 0.1206 - emotion_output_loss: 0.4204 - gender_output_acc: 0.9735 - image_quality_output_acc: 0.9339 - age_output_acc: 0.7627 - weight_output_acc: 0.8671 - bag_output_acc: 0.9029 - footwear_output_acc: 0.8772 - pose_output_acc: 0.9567 - emotion_output_acc: 0.8296 - val_loss: 5.7369 - val_gender_output_loss: 0.1634 - val_image_quality_output_loss: 0.1768 - val_age_output_loss: 2.0851 - val_weight_output_loss: 0.9221 - val_bag_output_loss: 0.1749 - val_footwear_output_loss: 0.3657 - val_pose_output_loss: 0.2565 - val_emotion_output_loss: 0.5197 - val_gender_output_acc: 0.9396 - val_image_quality_output_acc: 0.9296 - val_age_output_acc: 0.2616 - val_weight_output_acc: 0.6115 - val_bag_output_acc: 0.9383 - val_footwear_output_acc: 0.8418 - val_pose_output_acc: 0.8952 - val_emotion_output_acc: 0.8122\n",
      "Epoch 79/100\n",
      "360/360 [==============================] - 41s 114ms/step - loss: 3.2584 - gender_output_loss: 0.0560 - image_quality_output_loss: 0.1798 - age_output_loss: 0.5693 - weight_output_loss: 0.3163 - bag_output_loss: 0.2454 - footwear_output_loss: 0.2817 - pose_output_loss: 0.1159 - emotion_output_loss: 0.4196 - gender_output_acc: 0.9757 - image_quality_output_acc: 0.9357 - age_output_acc: 0.7655 - weight_output_acc: 0.8763 - bag_output_acc: 0.9063 - footwear_output_acc: 0.8794 - pose_output_acc: 0.9543 - emotion_output_acc: 0.8289 - val_loss: 7.7315 - val_gender_output_loss: 0.0120 - val_image_quality_output_loss: 1.4399 - val_age_output_loss: 0.4645 - val_weight_output_loss: 0.2301 - val_bag_output_loss: 0.1378 - val_footwear_output_loss: 2.1415 - val_pose_output_loss: 0.1880 - val_emotion_output_loss: 2.0401 - val_gender_output_acc: 0.9957 - val_image_quality_output_acc: 0.5608 - val_age_output_acc: 0.8323 - val_weight_output_acc: 0.9080 - val_bag_output_acc: 0.9526 - val_footwear_output_acc: 0.5325 - val_pose_output_acc: 0.9377 - val_emotion_output_acc: 0.7213\n",
      "Epoch 80/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.2862 - gender_output_loss: 0.0676 - image_quality_output_loss: 0.1739 - age_output_loss: 0.5669 - weight_output_loss: 0.3258 - bag_output_loss: 0.2486 - footwear_output_loss: 0.2814 - pose_output_loss: 0.1167 - emotion_output_loss: 0.4257 - gender_output_acc: 0.9700 - image_quality_output_acc: 0.9359 - age_output_acc: 0.7661 - weight_output_acc: 0.8726 - bag_output_acc: 0.9076 - footwear_output_acc: 0.8824 - pose_output_acc: 0.9571 - emotion_output_acc: 0.8267 - val_loss: 12.1633 - val_gender_output_loss: 1.2022 - val_image_quality_output_loss: 5.0855 - val_age_output_loss: 1.8041 - val_weight_output_loss: 0.7088 - val_bag_output_loss: 0.8937 - val_footwear_output_loss: 0.3582 - val_pose_output_loss: 0.3809 - val_emotion_output_loss: 0.6463 - val_gender_output_acc: 0.7359 - val_image_quality_output_acc: 0.2138 - val_age_output_acc: 0.3675 - val_weight_output_acc: 0.6977 - val_bag_output_acc: 0.7582 - val_footwear_output_acc: 0.8276 - val_pose_output_acc: 0.8812 - val_emotion_output_acc: 0.7919\n",
      "Epoch 81/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.2765 - gender_output_loss: 0.0610 - image_quality_output_loss: 0.1747 - age_output_loss: 0.5703 - weight_output_loss: 0.3165 - bag_output_loss: 0.2430 - footwear_output_loss: 0.2861 - pose_output_loss: 0.1214 - emotion_output_loss: 0.4176 - gender_output_acc: 0.9735 - image_quality_output_acc: 0.9326 - age_output_acc: 0.7656 - weight_output_acc: 0.8746 - bag_output_acc: 0.9097 - footwear_output_acc: 0.8784 - pose_output_acc: 0.9554 - emotion_output_acc: 0.8300 - val_loss: 18.4762 - val_gender_output_loss: 0.4997 - val_image_quality_output_loss: 2.9102 - val_age_output_loss: 0.4060 - val_weight_output_loss: 0.3660 - val_bag_output_loss: 1.6996 - val_footwear_output_loss: 7.2273 - val_pose_output_loss: 2.1813 - val_emotion_output_loss: 2.0961 - val_gender_output_acc: 0.8310 - val_image_quality_output_acc: 0.3275 - val_age_output_acc: 0.8464 - val_weight_output_acc: 0.8428 - val_bag_output_acc: 0.5045 - val_footwear_output_acc: 0.3725 - val_pose_output_acc: 0.6615 - val_emotion_output_acc: 0.3119\n",
      "Epoch 82/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.2581 - gender_output_loss: 0.0685 - image_quality_output_loss: 0.1796 - age_output_loss: 0.5632 - weight_output_loss: 0.3168 - bag_output_loss: 0.2392 - footwear_output_loss: 0.2754 - pose_output_loss: 0.1171 - emotion_output_loss: 0.4068 - gender_output_acc: 0.9690 - image_quality_output_acc: 0.9325 - age_output_acc: 0.7673 - weight_output_acc: 0.8773 - bag_output_acc: 0.9105 - footwear_output_acc: 0.8856 - pose_output_acc: 0.9553 - emotion_output_acc: 0.8333 - val_loss: 5.7913 - val_gender_output_loss: 0.4773 - val_image_quality_output_loss: 0.3540 - val_age_output_loss: 0.7341 - val_weight_output_loss: 0.8684 - val_bag_output_loss: 0.6136 - val_footwear_output_loss: 0.3374 - val_pose_output_loss: 0.1005 - val_emotion_output_loss: 1.2117 - val_gender_output_acc: 0.8521 - val_image_quality_output_acc: 0.8658 - val_age_output_acc: 0.6542 - val_weight_output_acc: 0.6684 - val_bag_output_acc: 0.8072 - val_footwear_output_acc: 0.8444 - val_pose_output_acc: 0.9573 - val_emotion_output_acc: 0.5769\n",
      "Epoch 83/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 3.2592 - gender_output_loss: 0.0588 - image_quality_output_loss: 0.1803 - age_output_loss: 0.5623 - weight_output_loss: 0.3269 - bag_output_loss: 0.2283 - footwear_output_loss: 0.2734 - pose_output_loss: 0.1175 - emotion_output_loss: 0.4155 - gender_output_acc: 0.9749 - image_quality_output_acc: 0.9338 - age_output_acc: 0.7655 - weight_output_acc: 0.8727 - bag_output_acc: 0.9168 - footwear_output_acc: 0.8833 - pose_output_acc: 0.9578 - emotion_output_acc: 0.8304 - val_loss: 8.3490 - val_gender_output_loss: 0.0100 - val_image_quality_output_loss: 1.6758 - val_age_output_loss: 0.7663 - val_weight_output_loss: 1.2830 - val_bag_output_loss: 2.1675 - val_footwear_output_loss: 0.3771 - val_pose_output_loss: 0.5979 - val_emotion_output_loss: 0.3716 - val_gender_output_acc: 0.9966 - val_image_quality_output_acc: 0.5385 - val_age_output_acc: 0.6514 - val_weight_output_acc: 0.3978 - val_bag_output_acc: 0.5591 - val_footwear_output_acc: 0.8674 - val_pose_output_acc: 0.8289 - val_emotion_output_acc: 0.8269\n",
      "Epoch 84/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.2380 - gender_output_loss: 0.0621 - image_quality_output_loss: 0.1634 - age_output_loss: 0.5597 - weight_output_loss: 0.3123 - bag_output_loss: 0.2489 - footwear_output_loss: 0.2670 - pose_output_loss: 0.1151 - emotion_output_loss: 0.4088 - gender_output_acc: 0.9727 - image_quality_output_acc: 0.9409 - age_output_acc: 0.7711 - weight_output_acc: 0.8797 - bag_output_acc: 0.9066 - footwear_output_acc: 0.8873 - pose_output_acc: 0.9556 - emotion_output_acc: 0.8303 - val_loss: 5.3930 - val_gender_output_loss: 0.2082 - val_image_quality_output_loss: 0.2815 - val_age_output_loss: 1.3647 - val_weight_output_loss: 0.1730 - val_bag_output_loss: 0.1609 - val_footwear_output_loss: 0.4849 - val_pose_output_loss: 0.1702 - val_emotion_output_loss: 1.4474 - val_gender_output_acc: 0.9283 - val_image_quality_output_acc: 0.8920 - val_age_output_acc: 0.4081 - val_weight_output_acc: 0.9424 - val_bag_output_acc: 0.9451 - val_footwear_output_acc: 0.8273 - val_pose_output_acc: 0.9393 - val_emotion_output_acc: 0.7385\n",
      "Epoch 85/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.1857 - gender_output_loss: 0.0576 - image_quality_output_loss: 0.1774 - age_output_loss: 0.5414 - weight_output_loss: 0.3079 - bag_output_loss: 0.2243 - footwear_output_loss: 0.2573 - pose_output_loss: 0.1121 - emotion_output_loss: 0.4045 - gender_output_acc: 0.9732 - image_quality_output_acc: 0.9348 - age_output_acc: 0.7768 - weight_output_acc: 0.8806 - bag_output_acc: 0.9172 - footwear_output_acc: 0.8957 - pose_output_acc: 0.9568 - emotion_output_acc: 0.8345 - val_loss: 5.3261 - val_gender_output_loss: 0.0994 - val_image_quality_output_loss: 1.2019 - val_age_output_loss: 0.5683 - val_weight_output_loss: 0.3548 - val_bag_output_loss: 0.1482 - val_footwear_output_loss: 0.6215 - val_pose_output_loss: 0.0795 - val_emotion_output_loss: 1.1475 - val_gender_output_acc: 0.9611 - val_image_quality_output_acc: 0.6262 - val_age_output_acc: 0.7776 - val_weight_output_acc: 0.8527 - val_bag_output_acc: 0.9525 - val_footwear_output_acc: 0.7886 - val_pose_output_acc: 0.9684 - val_emotion_output_acc: 0.5922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "359/360 [============================>.] - ETA: 0s - loss: 3.2014 - gender_output_loss: 0.0660 - image_quality_output_loss: 0.1654 - age_output_loss: 0.5527 - weight_output_loss: 0.3036 - bag_output_loss: 0.2269 - footwear_output_loss: 0.2607 - pose_output_loss: 0.1068 - emotion_output_loss: 0.4121 - gender_output_acc: 0.9712 - image_quality_output_acc: 0.9426 - age_output_acc: 0.7752 - weight_output_acc: 0.8804 - bag_output_acc: 0.9165 - footwear_output_acc: 0.8933 - pose_output_acc: 0.9584 - emotion_output_acc: 0.8308Epoch 86/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.2043 - gender_output_loss: 0.0662 - image_quality_output_loss: 0.1651 - age_output_loss: 0.5538 - weight_output_loss: 0.3035 - bag_output_loss: 0.2281 - footwear_output_loss: 0.2615 - pose_output_loss: 0.1069 - emotion_output_loss: 0.4119 - gender_output_acc: 0.9710 - image_quality_output_acc: 0.9428 - age_output_acc: 0.7746 - weight_output_acc: 0.8805 - bag_output_acc: 0.9161 - footwear_output_acc: 0.8929 - pose_output_acc: 0.9584 - emotion_output_acc: 0.8307 - val_loss: 3.6172 - val_gender_output_loss: 0.0157 - val_image_quality_output_loss: 0.2326 - val_age_output_loss: 0.4036 - val_weight_output_loss: 0.6446 - val_bag_output_loss: 0.2601 - val_footwear_output_loss: 0.5255 - val_pose_output_loss: 0.0671 - val_emotion_output_loss: 0.3569 - val_gender_output_acc: 0.9945 - val_image_quality_output_acc: 0.9146 - val_age_output_acc: 0.8319 - val_weight_output_acc: 0.7639 - val_bag_output_acc: 0.9049 - val_footwear_output_acc: 0.7974 - val_pose_output_acc: 0.9727 - val_emotion_output_acc: 0.8477\n",
      "Epoch 87/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.2298 - gender_output_loss: 0.0660 - image_quality_output_loss: 0.1764 - age_output_loss: 0.5686 - weight_output_loss: 0.3027 - bag_output_loss: 0.2253 - footwear_output_loss: 0.2590 - pose_output_loss: 0.1103 - emotion_output_loss: 0.4086 - gender_output_acc: 0.9714 - image_quality_output_acc: 0.9366 - age_output_acc: 0.7607 - weight_output_acc: 0.8846 - bag_output_acc: 0.9149 - footwear_output_acc: 0.8926 - pose_output_acc: 0.9576 - emotion_output_acc: 0.8350 - val_loss: 12.1676 - val_gender_output_loss: 1.3406 - val_image_quality_output_loss: 0.0877 - val_age_output_loss: 3.6970 - val_weight_output_loss: 2.2516 - val_bag_output_loss: 0.9195 - val_footwear_output_loss: 1.5791 - val_pose_output_loss: 0.6941 - val_emotion_output_loss: 0.4827 - val_gender_output_acc: 0.6901 - val_image_quality_output_acc: 0.9701 - val_age_output_acc: 0.1978 - val_weight_output_acc: 0.3423 - val_bag_output_acc: 0.7265 - val_footwear_output_acc: 0.4598 - val_pose_output_acc: 0.8277 - val_emotion_output_acc: 0.7962\n",
      "Epoch 88/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.2294 - gender_output_loss: 0.0625 - image_quality_output_loss: 0.1681 - age_output_loss: 0.5591 - weight_output_loss: 0.3015 - bag_output_loss: 0.2300 - footwear_output_loss: 0.2661 - pose_output_loss: 0.1142 - emotion_output_loss: 0.4094 - gender_output_acc: 0.9738 - image_quality_output_acc: 0.9379 - age_output_acc: 0.7693 - weight_output_acc: 0.8822 - bag_output_acc: 0.9163 - footwear_output_acc: 0.8911 - pose_output_acc: 0.9570 - emotion_output_acc: 0.8332 - val_loss: 5.8521 - val_gender_output_loss: 0.0576 - val_image_quality_output_loss: 0.1390 - val_age_output_loss: 1.4158 - val_weight_output_loss: 0.3229 - val_bag_output_loss: 0.2395 - val_footwear_output_loss: 0.3075 - val_pose_output_loss: 1.8933 - val_emotion_output_loss: 0.3543 - val_gender_output_acc: 0.9795 - val_image_quality_output_acc: 0.9459 - val_age_output_acc: 0.4011 - val_weight_output_acc: 0.8634 - val_bag_output_acc: 0.8976 - val_footwear_output_acc: 0.8840 - val_pose_output_acc: 0.5683 - val_emotion_output_acc: 0.8450\n",
      "Epoch 89/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.1758 - gender_output_loss: 0.0632 - image_quality_output_loss: 0.1707 - age_output_loss: 0.5460 - weight_output_loss: 0.2951 - bag_output_loss: 0.2193 - footwear_output_loss: 0.2407 - pose_output_loss: 0.1117 - emotion_output_loss: 0.4067 - gender_output_acc: 0.9734 - image_quality_output_acc: 0.9370 - age_output_acc: 0.7754 - weight_output_acc: 0.8816 - bag_output_acc: 0.9168 - footwear_output_acc: 0.9031 - pose_output_acc: 0.9565 - emotion_output_acc: 0.8346 - val_loss: 8.0426 - val_gender_output_loss: 0.0479 - val_image_quality_output_loss: 0.3823 - val_age_output_loss: 0.4038 - val_weight_output_loss: 3.6711 - val_bag_output_loss: 0.1841 - val_footwear_output_loss: 0.8732 - val_pose_output_loss: 0.0636 - val_emotion_output_loss: 1.2923 - val_gender_output_acc: 0.9806 - val_image_quality_output_acc: 0.8682 - val_age_output_acc: 0.8162 - val_weight_output_acc: 0.1365 - val_bag_output_acc: 0.9299 - val_footwear_output_acc: 0.7649 - val_pose_output_acc: 0.9758 - val_emotion_output_acc: 0.7481\n",
      "Epoch 90/100\n",
      "Epoch 89/100\n",
      "360/360 [==============================] - 41s 114ms/step - loss: 3.2116 - gender_output_loss: 0.0648 - image_quality_output_loss: 0.1596 - age_output_loss: 0.5656 - weight_output_loss: 0.3077 - bag_output_loss: 0.2228 - footwear_output_loss: 0.2486 - pose_output_loss: 0.1058 - emotion_output_loss: 0.4100 - gender_output_acc: 0.9708 - image_quality_output_acc: 0.9430 - age_output_acc: 0.7676 - weight_output_acc: 0.8834 - bag_output_acc: 0.9159 - footwear_output_acc: 0.8957 - pose_output_acc: 0.9590 - emotion_output_acc: 0.8352 - val_loss: 8.9806 - val_gender_output_loss: 0.0686 - val_image_quality_output_loss: 1.3851 - val_age_output_loss: 1.5141 - val_weight_output_loss: 2.5962 - val_bag_output_loss: 0.2896 - val_footwear_output_loss: 0.6249 - val_pose_output_loss: 0.9542 - val_emotion_output_loss: 0.4181 - val_gender_output_acc: 0.9736 - val_image_quality_output_acc: 0.5176 - val_age_output_acc: 0.3455 - val_weight_output_acc: 0.1396 - val_bag_output_acc: 0.8737 - val_footwear_output_acc: 0.7090 - val_pose_output_acc: 0.7624 - val_emotion_output_acc: 0.8368\n",
      "Epoch 91/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 3.1960 - gender_output_loss: 0.0658 - image_quality_output_loss: 0.1723 - age_output_loss: 0.5514 - weight_output_loss: 0.3055 - bag_output_loss: 0.2100 - footwear_output_loss: 0.2468 - pose_output_loss: 0.1075 - emotion_output_loss: 0.4045 - gender_output_acc: 0.9720 - image_quality_output_acc: 0.9398 - age_output_acc: 0.7720 - weight_output_acc: 0.8817 - bag_output_acc: 0.9221 - footwear_output_acc: 0.8984 - pose_output_acc: 0.9582 - emotion_output_acc: 0.8345 - val_loss: 7.0355 - val_gender_output_loss: 0.7564 - val_image_quality_output_loss: 0.1820 - val_age_output_loss: 0.4408 - val_weight_output_loss: 0.5121 - val_bag_output_loss: 1.3040 - val_footwear_output_loss: 0.3106 - val_pose_output_loss: 0.1615 - val_emotion_output_loss: 2.2326 - val_gender_output_acc: 0.7774 - val_image_quality_output_acc: 0.9352 - val_age_output_acc: 0.8211 - val_weight_output_acc: 0.8084 - val_bag_output_acc: 0.7026 - val_footwear_output_acc: 0.8641 - val_pose_output_acc: 0.9324 - val_emotion_output_acc: 0.3808\n",
      "Epoch 92/100\n",
      "360/360 [==============================] - 41s 114ms/step - loss: 3.2014 - gender_output_loss: 0.0658 - image_quality_output_loss: 0.1754 - age_output_loss: 0.5463 - weight_output_loss: 0.3034 - bag_output_loss: 0.2181 - footwear_output_loss: 0.2494 - pose_output_loss: 0.1067 - emotion_output_loss: 0.3993 - gender_output_acc: 0.9723 - image_quality_output_acc: 0.9354 - age_output_acc: 0.7758 - weight_output_acc: 0.8845 - bag_output_acc: 0.9197 - footwear_output_acc: 0.8993 - pose_output_acc: 0.9589 - emotion_output_acc: 0.8399 - val_loss: 8.5984 - val_gender_output_loss: 0.1214 - val_image_quality_output_loss: 1.4754 - val_age_output_loss: 2.9923 - val_weight_output_loss: 1.2783 - val_bag_output_loss: 0.9241 - val_footwear_output_loss: 0.2442 - val_pose_output_loss: 0.0288 - val_emotion_output_loss: 0.3945 - val_gender_output_acc: 0.9537 - val_image_quality_output_acc: 0.6735 - val_age_output_acc: 0.2174 - val_weight_output_acc: 0.5428 - val_bag_output_acc: 0.6794 - val_footwear_output_acc: 0.9246 - val_pose_output_acc: 0.9907 - val_emotion_output_acc: 0.8373\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 40s 111ms/step - loss: 3.1745 - gender_output_loss: 0.0657 - image_quality_output_loss: 0.1564 - age_output_loss: 0.5534 - weight_output_loss: 0.2984 - bag_output_loss: 0.2128 - footwear_output_loss: 0.2398 - pose_output_loss: 0.1136 - emotion_output_loss: 0.3938 - gender_output_acc: 0.9699 - image_quality_output_acc: 0.9428 - age_output_acc: 0.7734 - weight_output_acc: 0.8827 - bag_output_acc: 0.9206 - footwear_output_acc: 0.9029 - pose_output_acc: 0.9570 - emotion_output_acc: 0.8359 - val_loss: 7.1220 - val_gender_output_loss: 2.1509 - val_image_quality_output_loss: 0.7754 - val_age_output_loss: 0.4361 - val_weight_output_loss: 0.2095 - val_bag_output_loss: 0.6589 - val_footwear_output_loss: 0.4039 - val_pose_output_loss: 0.8402 - val_emotion_output_loss: 0.5028 - val_gender_output_acc: 0.6572 - val_image_quality_output_acc: 0.7507 - val_age_output_acc: 0.8147 - val_weight_output_acc: 0.9101 - val_bag_output_acc: 0.7483 - val_footwear_output_acc: 0.8165 - val_pose_output_acc: 0.7391 - val_emotion_output_acc: 0.8109\n",
      "Epoch 94/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.1811 - gender_output_loss: 0.0579 - image_quality_output_loss: 0.1581 - age_output_loss: 0.5513 - weight_output_loss: 0.2988 - bag_output_loss: 0.2133 - footwear_output_loss: 0.2487 - pose_output_loss: 0.1115 - emotion_output_loss: 0.3957 - gender_output_acc: 0.9748 - image_quality_output_acc: 0.9414 - age_output_acc: 0.7755 - weight_output_acc: 0.8835 - bag_output_acc: 0.9200 - footwear_output_acc: 0.8990 - pose_output_acc: 0.9578 - emotion_output_acc: 0.8371 - val_loss: 8.2553 - val_gender_output_loss: 0.0260 - val_image_quality_output_loss: 0.1078 - val_age_output_loss: 1.1913 - val_weight_output_loss: 0.5639 - val_bag_output_loss: 1.8195 - val_footwear_output_loss: 0.7758 - val_pose_output_loss: 0.1381 - val_emotion_output_loss: 2.4851 - val_gender_output_acc: 0.9906 - val_image_quality_output_acc: 0.9624 - val_age_output_acc: 0.4938 - val_weight_output_acc: 0.8070 - val_bag_output_acc: 0.6726 - val_footwear_output_acc: 0.7847 - val_pose_output_acc: 0.9502 - val_emotion_output_acc: 0.7220\n",
      "Epoch 95/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.1871 - gender_output_loss: 0.0658 - image_quality_output_loss: 0.1671 - age_output_loss: 0.5592 - weight_output_loss: 0.2969 - bag_output_loss: 0.2033 - footwear_output_loss: 0.2475 - pose_output_loss: 0.1046 - emotion_output_loss: 0.3924 - gender_output_acc: 0.9721 - image_quality_output_acc: 0.9392 - age_output_acc: 0.7658 - weight_output_acc: 0.8854 - bag_output_acc: 0.9234 - footwear_output_acc: 0.9002 - pose_output_acc: 0.9599 - emotion_output_acc: 0.8393 - val_loss: 8.1056 - val_gender_output_loss: 0.0572 - val_image_quality_output_loss: 3.1695 - val_age_output_loss: 0.4217 - val_weight_output_loss: 0.2521 - val_bag_output_loss: 0.5607 - val_footwear_output_loss: 0.5080 - val_pose_output_loss: 1.5362 - val_emotion_output_loss: 0.4474 - val_gender_output_acc: 0.9778 - val_image_quality_output_acc: 0.3547 - val_age_output_acc: 0.8255 - val_weight_output_acc: 0.9128 - val_bag_output_acc: 0.8470 - val_footwear_output_acc: 0.7984 - val_pose_output_acc: 0.6332 - val_emotion_output_acc: 0.8290\n",
      "Epoch 96/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.1780 - gender_output_loss: 0.0567 - image_quality_output_loss: 0.1587 - age_output_loss: 0.5528 - weight_output_loss: 0.2985 - bag_output_loss: 0.2106 - footwear_output_loss: 0.2367 - pose_output_loss: 0.1125 - emotion_output_loss: 0.3973 - gender_output_acc: 0.9743 - image_quality_output_acc: 0.9413 - age_output_acc: 0.7723 - weight_output_acc: 0.8874 - bag_output_acc: 0.9176 - footwear_output_acc: 0.9018 - pose_output_acc: 0.9559 - emotion_output_acc: 0.8364 - val_loss: 10.1655 - val_gender_output_loss: 2.0235 - val_image_quality_output_loss: 0.2414 - val_age_output_loss: 2.7188 - val_weight_output_loss: 0.4042 - val_bag_output_loss: 1.7029 - val_footwear_output_loss: 1.4182 - val_pose_output_loss: 0.1330 - val_emotion_output_loss: 0.3667 - val_gender_output_acc: 0.6177 - val_image_quality_output_acc: 0.9097 - val_age_output_acc: 0.2160 - val_weight_output_acc: 0.8322 - val_bag_output_acc: 0.5266 - val_footwear_output_acc: 0.6377 - val_pose_output_acc: 0.9470 - val_emotion_output_acc: 0.8387\n",
      "Epoch 97/100\n",
      "360/360 [==============================] - 40s 111ms/step - loss: 3.1819 - gender_output_loss: 0.0642 - image_quality_output_loss: 0.1729 - age_output_loss: 0.5499 - weight_output_loss: 0.3008 - bag_output_loss: 0.1999 - footwear_output_loss: 0.2361 - pose_output_loss: 0.1061 - emotion_output_loss: 0.3933 - gender_output_acc: 0.9729 - image_quality_output_acc: 0.9385 - age_output_acc: 0.7721 - weight_output_acc: 0.8835 - bag_output_acc: 0.9255 - footwear_output_acc: 0.9043 - pose_output_acc: 0.9585 - emotion_output_acc: 0.8369 - val_loss: 10.4618 - val_gender_output_loss: 0.3431 - val_image_quality_output_loss: 6.3490 - val_age_output_loss: 1.0660 - val_weight_output_loss: 0.1996 - val_bag_output_loss: 0.3137 - val_footwear_output_loss: 0.2031 - val_pose_output_loss: 0.0294 - val_emotion_output_loss: 0.7964 - val_gender_output_acc: 0.8890 - val_image_quality_output_acc: 0.2887 - val_age_output_acc: 0.5291 - val_weight_output_acc: 0.9170 - val_bag_output_acc: 0.9016 - val_footwear_output_acc: 0.9151 - val_pose_output_acc: 0.9898 - val_emotion_output_acc: 0.7927\n",
      "Epoch 98/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.1931 - gender_output_loss: 0.0628 - image_quality_output_loss: 0.1761 - age_output_loss: 0.5517 - weight_output_loss: 0.2913 - bag_output_loss: 0.2057 - footwear_output_loss: 0.2307 - pose_output_loss: 0.1125 - emotion_output_loss: 0.3984 - gender_output_acc: 0.9727 - image_quality_output_acc: 0.9385 - age_output_acc: 0.7735 - weight_output_acc: 0.8853 - bag_output_acc: 0.9247 - footwear_output_acc: 0.9089 - pose_output_acc: 0.9585 - emotion_output_acc: 0.8380 - val_loss: 7.8654 - val_gender_output_loss: 0.0726 - val_image_quality_output_loss: 3.1567 - val_age_output_loss: 0.4174 - val_weight_output_loss: 1.2768 - val_bag_output_loss: 1.0056 - val_footwear_output_loss: 0.1790 - val_pose_output_loss: 0.0292 - val_emotion_output_loss: 0.5615 - val_gender_output_acc: 0.9724 - val_image_quality_output_acc: 0.4747 - val_age_output_acc: 0.8262 - val_weight_output_acc: 0.5305 - val_bag_output_acc: 0.7516 - val_footwear_output_acc: 0.9331 - val_pose_output_acc: 0.9896 - val_emotion_output_acc: 0.8076\n",
      "Epoch 99/100\n",
      "360/360 [==============================] - 41s 113ms/step - loss: 3.1928 - gender_output_loss: 0.0646 - image_quality_output_loss: 0.1717 - age_output_loss: 0.5652 - weight_output_loss: 0.2922 - bag_output_loss: 0.2043 - footwear_output_loss: 0.2290 - pose_output_loss: 0.1088 - emotion_output_loss: 0.3892 - gender_output_acc: 0.9724 - image_quality_output_acc: 0.9395 - age_output_acc: 0.7687 - weight_output_acc: 0.8872 - bag_output_acc: 0.9222 - footwear_output_acc: 0.9076 - pose_output_acc: 0.9589 - emotion_output_acc: 0.8411 - val_loss: 12.6249 - val_gender_output_loss: 0.2121 - val_image_quality_output_loss: 2.3010 - val_age_output_loss: 2.2730 - val_weight_output_loss: 0.1619 - val_bag_output_loss: 0.1355 - val_footwear_output_loss: 0.2494 - val_pose_output_loss: 0.5213 - val_emotion_output_loss: 5.6009 - val_gender_output_acc: 0.9161 - val_image_quality_output_acc: 0.4024 - val_age_output_acc: 0.2510 - val_weight_output_acc: 0.9482 - val_bag_output_acc: 0.9482 - val_footwear_output_acc: 0.8973 - val_pose_output_acc: 0.8649 - val_emotion_output_acc: 0.1643\n",
      "Epoch 100/100\n",
      "360/360 [==============================] - 40s 112ms/step - loss: 3.1572 - gender_output_loss: 0.0609 - image_quality_output_loss: 0.1699 - age_output_loss: 0.5558 - weight_output_loss: 0.2939 - bag_output_loss: 0.2012 - footwear_output_loss: 0.2154 - pose_output_loss: 0.1062 - emotion_output_loss: 0.3831 - gender_output_acc: 0.9720 - image_quality_output_acc: 0.9407 - age_output_acc: 0.7718 - weight_output_acc: 0.8891 - bag_output_acc: 0.9233 - footwear_output_acc: 0.9117 - pose_output_acc: 0.9610 - emotion_output_acc: 0.8400 - val_loss: 15.4971 - val_gender_output_loss: 0.3042 - val_image_quality_output_loss: 3.8313 - val_age_output_loss: 0.4593 - val_weight_output_loss: 0.4359 - val_bag_output_loss: 3.9198 - val_footwear_output_loss: 5.0072 - val_pose_output_loss: 0.0444 - val_emotion_output_loss: 0.3226 - val_gender_output_acc: 0.8722 - val_image_quality_output_acc: 0.2918 - val_age_output_acc: 0.8037 - val_weight_output_acc: 0.8344 - val_bag_output_acc: 0.3662 - val_footwear_output_acc: 0.3836 - val_pose_output_acc: 0.9859 - val_emotion_output_acc: 0.8496\n"
     ]
    }
   ],
   "source": [
    "model_info = model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    use_multiprocessing=True,\n",
    "    workers=8,\n",
    "    epochs=100,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 16s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 15.497084771262275,\n",
       " 'gender_output_loss': 0.30423638543321024,\n",
       " 'image_quality_output_loss': 3.8313065648078917,\n",
       " 'age_output_loss': 0.4593281818760766,\n",
       " 'weight_output_loss': 0.4359119684331947,\n",
       " 'bag_output_loss': 3.9197689983579846,\n",
       " 'footwear_output_loss': 5.007244143221113,\n",
       " 'pose_output_loss': 0.044429559168768014,\n",
       " 'emotion_output_loss': 0.32259608548548485,\n",
       " 'gender_output_acc': 0.8722222222222222,\n",
       " 'image_quality_output_acc': 0.29184027777777777,\n",
       " 'age_output_acc': 0.8037326388888889,\n",
       " 'weight_output_acc': 0.834375,\n",
       " 'bag_output_acc': 0.3662326388888889,\n",
       " 'footwear_output_acc': 0.38359375,\n",
       " 'pose_output_acc': 0.9858506944444444,\n",
       " 'emotion_output_acc': 0.8495659722222222}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "results = model.evaluate_generator(valid_gen, verbose=1)\n",
    "dict(zip(model.metrics_names, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload failed: ./PersonAttributes.ipynb to s3://dl-ci-test/final/PersonAttributes.ipynb An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./PersonAttributes.ipynb s3://dl-ci-test/final/PersonAttributes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
